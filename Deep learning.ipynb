{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Deep learning.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tcd-h0csCpOe"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hpuwVkH4MJX"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "import os, shutil\n",
        "from os import path\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import zipfile\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import models \n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd \n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from keras.preprocessing import image\n",
        "from keras import backend as K\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from PIL import Image\n",
        "from PIL import ImageFile\n",
        "import random\n",
        "\n",
        "# Set a random seed\n",
        "from numpy.random import seed\n",
        "seed(1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxQ6ipNwDDwK"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjBaSySh_W6c"
      },
      "source": [
        "#Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ5gAhuh5FUd",
        "outputId": "2ee986d1-f320-4ebf-eee6-2e0266007f86"
      },
      "source": [
        "#Choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('~/data')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "#Auto-iterate using the query syntax\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1tQbRH3uO-mwTbViQTNdzs_4x-UnUkoSz' in parents\"}).GetList()\n",
        "\n",
        "for f in file_list:\n",
        "  #Create & download by id.\n",
        "  print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  print('downloading to {}'.format(fname))\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)\n",
        "  break"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: DataSet.zip, id: 1BeacQpDbIvJCk93KrpJxxsoeAcS_8ySo\n",
            "downloading to /root/data/DataSet.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWiG4_vp5z2S"
      },
      "source": [
        "with zipfile.ZipFile('/root/data/DataSet.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/root/data')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44Llx0GdDNaT"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnY31jz3AD6X"
      },
      "source": [
        "#Code used to reorganize the data in to new splits\n",
        "\n",
        "# #Move all data to the same folders\n",
        "\n",
        "# #Destination folders\n",
        "# dst_normal = 'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/AllData/NORMAL'\n",
        "# dst_pneumonia = 'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/AllData/PNEUMONIA'\n",
        "\n",
        "# #Original folders\n",
        "# src_normal = ['C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/val/NORMAL',\n",
        "#              'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/test/NORMAL',\n",
        "#              'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/train/NORMAL']\n",
        "\n",
        "# src_pneumonia = ['C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/val/PNEUMONIA',\n",
        "#              'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/test/PNEUMONIA',\n",
        "#              'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/train/PNEUMONIA']\n",
        "\n",
        "# #Loop to copy data from original folders to destination folders\n",
        "# for j in src_normal:\n",
        "#     files = [i for i in os.listdir(j)]\n",
        "#     for f in files:\n",
        "#         shutil.copy(path.join(j, f), dst_normal)\n",
        "        \n",
        "# for j in src_pneumonia:\n",
        "#     files = [i for i in os.listdir(j)]\n",
        "#     for f in files:\n",
        "#         shutil.copy(path.join(j, f), dst_pneumonia)\n",
        "\n",
        "# #Create train, val, test split (70, 15, 15)\n",
        "\n",
        "# #Destination folders\n",
        "# dst_normal = ['C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet/train/NORMAL',\n",
        "#              'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet/val/NORMAL',\n",
        "#              'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet/test/NORMAL']\n",
        "\n",
        "# dst_pneumonia = ['C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet/train/PNEUMONIA',\n",
        "#              'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet/val/PNEUMONIA',\n",
        "#              'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet/test/PNEUMONIA']\n",
        "\n",
        "# #Source folders\n",
        "# src_normal = 'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/AllData/NORMAL'\n",
        "# src_pneumonia = 'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/AllData/PNEUMONIA'\n",
        "\n",
        "# #Files (images) in source folders\n",
        "# files_normal = [i for i in os.listdir(src_normal)]\n",
        "# files_pneumonia = [i for i in os.listdir(src_pneumonia)]\n",
        "\n",
        "# #Counters\n",
        "# count_normal = 1\n",
        "# count_pneumonia = 1\n",
        "\n",
        "# #Loops to copy images to destination folders\n",
        "# for f in files_normal:\n",
        "#     if count_normal <= 1108:\n",
        "#         shutil.copy(path.join(src_normal, f), dst_normal[0]) \n",
        "#     elif count_normal <= (1108+238):\n",
        "#         shutil.copy(path.join(src_normal, f), dst_normal[1])\n",
        "#     else:\n",
        "#         shutil.copy(path.join(src_normal, f), dst_normal[2])\n",
        "#     count_normal = count_normal + 1\n",
        "    \n",
        "# for f in files_pneumonia:\n",
        "#     if count_pneumonia <= 2993:\n",
        "#         shutil.copy(path.join(src_pneumonia, f), dst_pneumonia[0]) \n",
        "#     elif count_pneumonia <= (2993+640):\n",
        "#         shutil.copy(path.join(src_pneumonia, f), dst_pneumonia[1])\n",
        "#     else:\n",
        "#         shutil.copy(path.join(src_pneumonia, f), dst_pneumonia[2])\n",
        "#     count_pneumonia = count_pneumonia + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIxR-YssU7_O"
      },
      "source": [
        "#Code used to produce oversampling dataset trough data augmentation\n",
        "\n",
        "#Data augmentation used\n",
        "# train_augment_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "#                                   rotation_range=40,\n",
        "#                                   width_shift_range=0.2,\n",
        "#                                   height_shift_range=0.2,\n",
        "#                                   shear_range=0.2,\n",
        "#                                   zoom_range=0.2,\n",
        "#                                   fill_mode='nearest')\n",
        "\n",
        "# train_augment_set = train_augment_datagen.flow_from_directory('C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet/train/', \n",
        "#                                                  target_size = (75, 75),\n",
        "#                                                  batch_size = 20,\n",
        "#                                                  class_mode = 'binary',\n",
        "                                                 \n",
        "#                                                 )\n",
        "\n",
        "# count = 1\n",
        "\n",
        "# for images, labels in train_augment_set:\n",
        "#     for i in range(20):\n",
        "#         if labels[i] == 0: #If the data augmented image is of the minority label, save itt\n",
        "#             matplotlib.image.imsave('C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet_DataAugOversampling/train/NORMAL/augmented'+str(count)+'.jpeg', images[i])\n",
        "#             count = count + 1\n",
        "#             if count >= 1885: #When the desired number of images are created aand saved, stop the loop\n",
        "#                 break\n",
        "#     if count >= 1885:\n",
        "#         break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZUzTSo7DZoU"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "#Generator for augmented data\n",
        "train_augment_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  rotation_range=40,\n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  shear_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                  fill_mode='nearest')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bbl3h3wDsMa",
        "outputId": "30f5fdb7-d8c3-42b0-bb9e-ad320aa09193"
      },
      "source": [
        "train_set = train_datagen.flow_from_directory('/root/data/DataSet/train/', \n",
        "                                                 target_size = (75, 75),\n",
        "                                                 batch_size = 20,\n",
        "                                                 class_mode = 'binary',\n",
        "                                                 seed=1\n",
        "                                                )\n",
        "\n",
        "train_augment_set = train_augment_datagen.flow_from_directory('/root/data/DataSet/train/', \n",
        "                                                 target_size = (75, 75),\n",
        "                                                 batch_size = 20,\n",
        "                                                 class_mode = 'binary',\n",
        "                                                 seed=1\n",
        "                                                )\n",
        "#To be used for the confusion matrix\n",
        "val_set = val_datagen.flow_from_directory('/root/data/DataSet/val/', \n",
        "                                            target_size = (75, 75),\n",
        "                                            batch_size = 20,\n",
        "                                            class_mode = 'binary',\n",
        "                                            seed=1\n",
        "                                           )\n",
        "\n",
        "val_set_cm = val_datagen.flow_from_directory('/root/data/DataSet/val/', \n",
        "                                            target_size = (75, 75),\n",
        "                                            batch_size = 1,\n",
        "                                            class_mode = 'binary',\n",
        "                                            seed=1,\n",
        "                                            shuffle=False\n",
        "                                           )\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/root/data/DataSet/test/', \n",
        "                                            target_size = (75, 75),\n",
        "                                            batch_size = 20,\n",
        "                                            class_mode = 'binary',\n",
        "                                            seed=1,\n",
        "                                            shuffle = False\n",
        "                                           )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4101 images belonging to 2 classes.\n",
            "Found 878 images belonging to 2 classes.\n",
            "Found 878 images belonging to 2 classes.\n",
            "Found 877 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ0tO7Ld8qbW"
      },
      "source": [
        "# Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZoJ3dqx8vwW"
      },
      "source": [
        "#Create log directory\n",
        "!mkdir /root/data/logs\n",
        "\n",
        "#Load tensorboard\n",
        "%load_ext tensorboard\n",
        "\n",
        "#Launch tensorboard\n",
        "%tensorboard --logdir /root/data/logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F3h1xPeA48U"
      },
      "source": [
        "#Used when running a second model\n",
        "\n",
        "#Delete log folder\n",
        "#!rm -rf /root/data/logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHIJpp7NDTUg"
      },
      "source": [
        "# Model Creation and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSn2pyKJvSXl"
      },
      "source": [
        "callbacks_list= [keras.callbacks.TensorBoard(log_dir='/root/data/logs', histogram_freq=1),\n",
        "                 keras.callbacks.EarlyStopping(monitor = 'acc', patience=3), \n",
        "                 keras.callbacks.ModelCheckpoint(filepath=\"/root/data/DataSet/my_model.h5\", monitor =\"val_loss\", save_best_only=True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsj5fdZe4JOP"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(16, (3,3), activation='relu', input_shape=(75,75,3)))\n",
        "model.add(layers.Conv2D(32, (3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2), strides=2))\n",
        "model.add(layers.Conv2D(32, (3,3), activation='relu'))\n",
        "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2), strides=2))\n",
        "model.add(layers.Flatten())\n",
        "#model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001), activation='relu'))\n",
        "#model.add(layers.Dense(512, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001), activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WevBssSXC21"
      },
      "source": [
        "#model = models.load_model('/root/data/ReducedInputSizeModel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HheOplUw4JOV",
        "outputId": "b4ec89ba-cd30-49e7-bc31-b08e3cb4b031"
      },
      "source": [
        "hist= model.fit(\n",
        "        train_set,\n",
        "        steps_per_epoch= 205,\n",
        "        epochs= 50,\n",
        "        validation_data=val_set,\n",
        "        validation_steps=43, \n",
        "        callbacks=callbacks_list\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "205/205 [==============================] - 111s 536ms/step - loss: 11.7620 - acc: 0.7438 - val_loss: 1.5384 - val_acc: 0.8837\n",
            "Epoch 2/50\n",
            "205/205 [==============================] - 108s 524ms/step - loss: 1.4156 - acc: 0.8301 - val_loss: 1.0218 - val_acc: 0.8593\n",
            "Epoch 3/50\n",
            "205/205 [==============================] - 108s 528ms/step - loss: 0.9028 - acc: 0.8774 - val_loss: 0.6350 - val_acc: 0.9605\n",
            "Epoch 4/50\n",
            "205/205 [==============================] - 107s 521ms/step - loss: 0.6956 - acc: 0.8891 - val_loss: 0.7033 - val_acc: 0.8407\n",
            "Epoch 5/50\n",
            "205/205 [==============================] - 101s 492ms/step - loss: 0.5950 - acc: 0.9029 - val_loss: 0.4902 - val_acc: 0.9198\n",
            "Epoch 6/50\n",
            "205/205 [==============================] - 101s 492ms/step - loss: 0.5290 - acc: 0.9039 - val_loss: 0.3874 - val_acc: 0.9605\n",
            "Epoch 7/50\n",
            "205/205 [==============================] - 101s 492ms/step - loss: 0.4804 - acc: 0.9103 - val_loss: 0.3640 - val_acc: 0.9674\n",
            "Epoch 8/50\n",
            "205/205 [==============================] - 101s 492ms/step - loss: 0.4543 - acc: 0.9082 - val_loss: 0.3783 - val_acc: 0.9372\n",
            "Epoch 9/50\n",
            "205/205 [==============================] - 101s 491ms/step - loss: 0.4143 - acc: 0.9174 - val_loss: 0.3199 - val_acc: 0.9535\n",
            "Epoch 10/50\n",
            "205/205 [==============================] - 104s 507ms/step - loss: 0.3961 - acc: 0.9125 - val_loss: 0.2703 - val_acc: 0.9733\n",
            "Epoch 11/50\n",
            "205/205 [==============================] - 101s 491ms/step - loss: 0.3459 - acc: 0.9301 - val_loss: 0.2576 - val_acc: 0.9709\n",
            "Epoch 12/50\n",
            "205/205 [==============================] - 101s 490ms/step - loss: 0.3460 - acc: 0.9233 - val_loss: 0.2857 - val_acc: 0.9558\n",
            "Epoch 13/50\n",
            "205/205 [==============================] - 101s 491ms/step - loss: 0.3386 - acc: 0.9319 - val_loss: 0.2817 - val_acc: 0.9581\n",
            "Epoch 14/50\n",
            "205/205 [==============================] - 101s 491ms/step - loss: 0.3325 - acc: 0.9305 - val_loss: 0.2577 - val_acc: 0.9756\n",
            "Epoch 15/50\n",
            "205/205 [==============================] - 101s 491ms/step - loss: 0.3290 - acc: 0.9256 - val_loss: 0.3309 - val_acc: 0.9267\n",
            "Epoch 16/50\n",
            "205/205 [==============================] - 104s 506ms/step - loss: 0.3178 - acc: 0.9330 - val_loss: 0.2355 - val_acc: 0.9791\n",
            "Epoch 17/50\n",
            "205/205 [==============================] - 101s 493ms/step - loss: 0.3287 - acc: 0.9319 - val_loss: 0.2557 - val_acc: 0.9628\n",
            "Epoch 18/50\n",
            "205/205 [==============================] - 102s 495ms/step - loss: 0.3053 - acc: 0.9422 - val_loss: 0.2340 - val_acc: 0.9779\n",
            "Epoch 19/50\n",
            "205/205 [==============================] - 102s 497ms/step - loss: 0.3076 - acc: 0.9439 - val_loss: 0.2421 - val_acc: 0.9663\n",
            "Epoch 20/50\n",
            "205/205 [==============================] - 101s 493ms/step - loss: 0.2988 - acc: 0.9410 - val_loss: 0.2978 - val_acc: 0.9372\n",
            "Epoch 21/50\n",
            "205/205 [==============================] - 101s 491ms/step - loss: 0.2927 - acc: 0.9460 - val_loss: 0.2195 - val_acc: 0.9779\n",
            "Epoch 22/50\n",
            "205/205 [==============================] - 101s 492ms/step - loss: 0.3091 - acc: 0.9299 - val_loss: 0.2570 - val_acc: 0.9570\n",
            "Epoch 23/50\n",
            "205/205 [==============================] - 101s 491ms/step - loss: 0.2974 - acc: 0.9396 - val_loss: 0.2270 - val_acc: 0.9744\n",
            "Epoch 24/50\n",
            "205/205 [==============================] - 100s 488ms/step - loss: 0.2909 - acc: 0.9440 - val_loss: 0.2273 - val_acc: 0.9767\n",
            "Epoch 25/50\n",
            "205/205 [==============================] - 100s 489ms/step - loss: 0.3054 - acc: 0.9419 - val_loss: 0.2148 - val_acc: 0.9826\n",
            "Epoch 26/50\n",
            "205/205 [==============================] - 101s 490ms/step - loss: 0.2824 - acc: 0.9438 - val_loss: 0.2235 - val_acc: 0.9756\n",
            "Epoch 27/50\n",
            "205/205 [==============================] - 100s 489ms/step - loss: 0.2757 - acc: 0.9478 - val_loss: 0.2171 - val_acc: 0.9791\n",
            "Epoch 28/50\n",
            "205/205 [==============================] - 100s 489ms/step - loss: 0.2972 - acc: 0.9411 - val_loss: 0.2313 - val_acc: 0.9686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF8NUwdkFFbf"
      },
      "source": [
        "# Model Assessment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XocTFY634JOW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "b8648cd0-ae26-4c22-ce3c-4cbf09e49d8a"
      },
      "source": [
        "acc = hist.history['acc']\n",
        "val_acc = hist.history['val_acc']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc)+1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXgUVdb48e9JQJBFZBEhgCyKgo6yiiOIgiuIivjiAhkHRt9BcHd0XMaNQXH0FZdxUBz4uYsDLu+LMOLouK+jgAIqBkFMNIiAIPsSQs7vj9tNOk13Ut1dne5Uzud58nR3LbdudadP3zp165aoKsYYY4IrJ9MVMMYYk14W6I0xJuAs0BtjTMBZoDfGmICzQG+MMQFngd4YYwLOAn0tJCKvisgov5fNJBEpFJGT01CuisghoeePisitXpZNYjv5IvJ6svU0pjJi/ehrBhHZEvGyAbAT2B16fYmqTq/+WmUPESkE/ltV3/C5XAU6q+pyv5YVkQ7Ad0BdVS31o57GVKZOpitgvFHVRuHnlQU1EaljwcNkC/t/zA6WuqnhRGSAiBSLyA0i8hPwhIg0FZF/ishaEfkl9LxtxDrviMh/h56PFpEPRGRSaNnvRGRwkst2FJH3RGSziLwhIg+LyLNx6u2ljneIyIeh8l4XkRYR8y8UkSIRWSciN1fy/hwjIj+JSG7EtGEisjj0vI+IfCwiG0RklYhMFpF94pT1pIjcGfH6j6F1fhSRi6KWHSIin4vIJhH5QUTGR8x+L/S4QUS2iMix4fc2Yv2+IjJPRDaGHvt6fW8SfJ+bicgToX34RURmRcwbKiILQ/vwrYgMCk2vkCYTkfHhz1lEOoRSWBeLyPfAW6HpL4Q+h42h/5EjItbfV0TuC32eG0P/Y/uKyCsickXU/iwWkWGx9tXEZ4E+GFoBzYD2wBjc5/pE6PVBwHZgciXrHwMsBVoA/wM8JiKSxLLPAZ8CzYHxwIWVbNNLHUcCvwNaAvsA1wGIyOHAlFD5eaHttSUGVf0E2AqcGFXuc6Hnu4FrQvtzLHAScGkl9SZUh0Gh+pwCdAaizw9sBX4L7A8MAcaJyNmheceHHvdX1Uaq+nFU2c2AV4CHQvt2P/CKiDSP2oe93psYqnqfn8GlAo8IlfVAqA59gKeBP4b24XigMN77EcMJQFfgtNDrV3HvU0vgMyAy1TgJ6AX0xf0fXw+UAU8BvwkvJCLdgDa498YkQlXtr4b94b5wJ4eeDwBKgPqVLN8d+CXi9Tu41A/AaGB5xLwGgAKtElkWF0RKgQYR858FnvW4T7HqeEvE60uBf4We3wbMiJjXMPQenByn7DuBx0PPG+OCcPs4y14N/F/EawUOCT1/Ergz9Pxx4O6I5Q6NXDZGuQ8CD4SedwgtWydi/mjgg9DzC4FPo9b/GBhd1XuTyPsMtMYF1KYxlvt7uL6V/f+FXo8Pf84R+9apkjrsH1qmCe6HaDvQLcZy9YFfcOc9wP0gPFLd37cg/FmLPhjWquqO8AsRaSAifw8dCm/CpQr2j0xfRPkp/ERVt4WeNkpw2TxgfcQ0gB/iVdhjHX+KeL4tok55kWWr6lZgXbxt4Vrv54hIPeAc4DNVLQrV49BQOuOnUD3uwrXuq1KhDkBR1P4dIyJvh1ImG4GxHssNl10UNa0I15oNi/feVFDF+9wO95n9EmPVdsC3Husby573RkRyReTuUPpnE+VHBi1Cf/VjbSv0Pz0T+I2I5AAjcEcgJkEW6IMhuuvUtcBhwDGquh/lqYJ46Rg/rAKaiUiDiGntKlk+lTquiiw7tM3m8RZW1SW4QDmYimkbcCmgAlyrcT/gT8nUAXdEE+k5YDbQTlWbAI9GlFtVV7cfcamWSAcBKz3UK1pl7/MPuM9s/xjr/QAcHKfMrbijubBWMZaJ3MeRwFBceqsJrtUfrsPPwI5KtvUUkI9LqW3TqDSX8cYCfTA1xh0Obwjle29P9wZDLeT5wHgR2UdEjgXOTFMdXwTOEJHjQidOJ1D1//JzwFW4QPdCVD02AVtEpAswzmMdngdGi8jhoR+a6Po3xrWWd4Ty3SMj5q3FpUw6xSl7LnCoiIwUkToicj5wOPBPj3WLrkfM91lVV+Fy54+ETtrWFZHwD8FjwO9E5CQRyRGRNqH3B2AhcEFo+d7AcA912Ik76mqAO2oK16EMlwa7X0TyQq3/Y0NHX4QCexlwH9aaT5oF+mB6ENgX11r6D/CvatpuPu6E5jpcXnwm7gseS9J1VNWvgMtwwXsVLo9bXMVq/8CdIHxLVX+OmH4dLghvBqaF6uylDq+G9uEtYHnoMdKlwAQR2Yw7p/B8xLrbgInAh+J6+/w6qux1wBm41vg63MnJM6Lq7VVV7/OFwC7cUc0a3DkKVPVT3MneB4CNwLuUH2XcimuB/wL8mYpHSLE8jTuiWgksCdUj0nXAF8A8YD1wDxVj09PAkbhzPiYJdsGUSRsRmQkUqGrajyhMcInIb4ExqnpcputSU1mL3vhGRI4WkYNDh/qDcHnZWVWtZ0w8obTYpcDUTNelJrNAb/zUCtf1bwuuD/g4Vf08ozUyNZaInIY7n7GaqtNDphKWujHGmICzFr0xxgRc1g1q1qJFC+3QoUOmq2GMMTXKggULflbVA2LNy7pA36FDB+bPn5/pahhjTI0iItFXU+9hqRtjjAk4C/TGGBNwFuiNMSbgLNAbY0zAWaA3xpiAs0BvjDEBZ4HeGGMCzgK9MabWUoV33oGnnoKd8QbUDgAL9MaYWqesDF5+GY49FgYOhNGjoWtXePFFF/yDxgK9MabW2LULnn4ajjwSzj4b1qyBKVNg7lxo1AjOPRdOOAEWLMh0Tf1lgd6YarR4MWzZkula1D7btsHkydC5M4waBbm5MH06fPMNjB0LgwfD55/D3/8OS5dC795uuZXJ3KU3ZMcO+Phj2LTJv/1IlgV6Y6rJli3Qpw8MHQq7d/tbdmkprFjhb5nJ2LQJfvwx07Uot2ED3HUXdOgAV1wBbdrAnDmwaBGMHAl1Ikb7ys2FMWNg2TK44QaYMQMOPRT+/Gf3Q+HF8uXuB2XIEGjWDPr2dT8ay5alZfe8U9Ws+uvVq5caE0T//reqywCr3nabf+WWlamee66qiOojj/hXbjLy81WbN1f9+efM1aGsTPXbb1Wvv161cWP3fg8erPree4mVs2KFe19BtU0b1aefVt29u+IyW7eq/vOfqpdfrnrwweWfb+fOqldcoTptmmqLFqpNm6q+/bZvuxgTMF/jxNWMB/boPwv0JtPKytwX2G+33aaak1MelF97zZ9y77ijPLiA6t13+1NuonbuLA+sl15aPdssKVFdvNgF4WuuUR040AVVcO/1+eerfv55att4/33V3r1dmUcfrfryy6r33696yimq9eq56Q0aqA4Zojp5sury5RXX//Zb1S5dVOvWVX388dTqUhkL9MYk4L//W7V1a9Vdu/wt98QTVbt3dz8iv/qVa+kVF6dW5qxZ7lv8m9+4QHvBBe71n/7kfrCq0+uvu20fdZQLsgsX+lv+5s0u6P7tb6oXX6zas6fqPvuUt6Lr11ft00d1zBh3ZBMdcFOxe7f7MWnTpnx7Xbuq/uEPbr+3b698/V9+UT3pJLfeTTftfWTgBwv0xnj0wgvlX+RPP/Wv3JIS1+q7/HL3+uuvVRs2VD3uuOR/UL78UrVRI9fa3LbNTSstdT9U4LaVjoASzxVXqO67r+rKlS5907+/fz82S5ao7r9/+WfTvLnqySer/vGPqtOnq371lf8/zLFs2eJa9IWFia9bUuJ+hEB1+HD/jxot0JuMufJK9wU9/njVq65SfeIJdyi9c2ema7a34mJ32H/EEe6bcc89/pX96aeuzJkzy6dNn+6m3XBD4uWtW+dywq1a7X1UUFameu21ruzf/rZ6AmBZmWr79qpnneVe//3vbvvPPZd62Tt3qvbo4YL7yy+7/a3uoxW/lJWp3nefS90dfbTqjz/6V7YFepMR773n/sOOO0711792Ldpwi6xuXZfGGD1a9a9/VX33XdUNGzJX19273aF1gwaqS5e6w/LBg/0r/7773H5HB+VLLnHT58zxXtauXa41u88+qh99FHuZsjLVCRNc2eeco7pjR/J192LxYretadPc69JSl1rJy3Mpl1TccIMre9as1OuZLWbNcv9r7dqpLlrkT5kW6E2127nTBcv27d3hrqr78hcUqM6Y4b68p52m2rJlefAH1SOPdCevqls4EE+d6l6PG+fSIiUl/pQ/bJhqx457T9++3f3gNW3qPR1w9dWurl5O7D3wgFv2tNPSc4I57M473XZWrSqf9tFHbtqNNyZf7ttvu9bv73+fchWzzoIF7oewUSPXcydVFuhNtZs40XtL9ccfVefOdes0beqCfaqtwEQsXOhax0OHlqcEnn/e1f/jj1Mvv6xM9YADXBollmXLVPfbz51IrCql9cQTrl5XXeV9+4895k6OHndc+o6ajjnG1T/ab3/r3ttvvkm8zPXrXYu3c+fyxkLQFBe7tFROjjuyTSUlZYHeVKtly1wPiP/6r8TXff11908/bFj1nEjcts3l5Fu1Ul2zpnz66tXu2/GXv6S+jYKCikcLsbz4YtUB/OOPXdA86aTE8+4zZ6rWqePSKZH76YdVq1zd77xz73k//ui6XA4ZkliZZWWuB1GdOv6eFM9GW7a4Rka4W2ppaXLlWKCvZcrKytMjyf7TpLLtU05xX+5kuw6G0w3jx/tbt1iuvNJt69VX9553xBGqp56a+jb+3/9z21iyxFtdXnpp73nFxe7HqFOn5C9GeuUV9wPctWvq3TojhfcvXq753nvd/ETSE888E//HI4hKS1Wvu871ykm2VW+Bvhb5z39Ujz1W9+S8X3mlerf/3HNuuw89lHwZZWWqo0bFD3p++de/3DauuCL2/MsvdyfMUs3Tjx7teoxU9QXeudOlP/bbr2If8G3bXA+NRo1cl8pUvPOOK6djR/96fJx1ljsXE2//du5UPeww1UMO8XZS+Lvv3HvQr1/1N1QyLZWjWAv0tcD336uOHOk+0QMPdN3bWrVSPfPM6qvD+vXu5Grv3ql/Qbdvd3nfhg1djw6/rV3r3p8jjijvgx4tnE758MPUtnXIIe7Q3IvvvnPnKXr0cO9BWZm7GMrPXieffOJSItdem3pZ27a5vvPh6wPiee019ZQKKy115xIaN3ZDEBjvLNAH2ObNqrfc4g7J69VzV91t2uTm3Xyzy3cXFVVPXS65xG1vwQJ/ylu50l2h2qGDC8x+KStTPftsl++u7OrNtWvdN2TixOS3Fc5f33uv93Vmz3brjB2rOmmSez5hQvJ1iOW889z1Dan2xJkzx9Xv9derXnboUPfDXVnaKHwS/+mnU6tXbWSBPoB273bd61q3dp/i+ee71mCkwkLXNe2WW9Jfnw8/dPW45hp/y/3kE/cDNnCgf10dp01zdZ00qepljzzS9VlPVvhK20R77/zxj249EXcVpd8XCIWvcajsBLEXv/+9a317uQDu22/dZzliROz58+a5I43zz6+5F0RlkgX6gHnnHXdoDy6nW1lqYcgQl6LwK0jGUlLixm5p1y493SKfekr3XNKfqm++cXn3E0/0lg+98kqXmkj2gqOrrnLrJ3olcEmJ611z9NHpeU/LylS7dXPj0iQbVHfvdg2Nc8/1vs6tt7rPMnokyS1bVA891P0PrV+fXH1qOwv0Kdqyxd8BkpJVVOSucgTVtm1Vn3226mD1z3+65V98MX31uvtuTfuVi3/4g1a48jIZJSUucDZtqvrDD97W+b//c9t9//3kttmrl+qAAcmtu3t3ek9Gho9s3n03ufXDwzokkmbZutUF827dKu7bmDHu6CXdQ/kGmQX6FN1yiwsOmT6c7N/ftUYnTPCeWy0tVT3oINc6TIcVK1yL9eyz01N+2K5drqtj3bqqH3yQXBnh1uTzz3tfZ906F4CSyZFv2uTOWVRH6iwZW7e6/+tEWuSRbr3V7V+i3T3DF6M9/LB7HR6B8/rrk6uHcSzQp+i//su9U5m8mcLq1S7g3H574uuGL09futTfOpWVqQ4a5Lrrff+9v2XHsn6968HSsmVi2ysrcy3FnBzXbTNR3bu7VE+iwsP2+jXufDpcd51qbq73I5xI3bq5xkeiysrKx43/8ks3XHOPHtk50F1NUlmgt1sJelBY6B5TuX9kqubOdT3jzzor8XUvvtjdMm3qVH/r9MIL8K9/wR13QLt2/pYdS9OmMHs2bN/ubuwc6/Zuu3dDQYG7DdwNN8Bpp0GrVjBwILRvDw89lPh2BwyAjz6CnTsTW++DDyAnB37968S3WV0uvRTKyty9UhPx/ffudnzJ/D+KwN/+5m472KePu8Xi9Omwzz6Jl2U8ivcLkKm/bGzRt2ihca+erC7DhrmbHiSbPjr3XNVmzeL3GU/Uhg3uJG+PHtUzDG6kOXPc0c0FF7heOY8+6roixhohs0cP1d/9zo0jkkyrVdUNjQvuJHgiBg502892Z57pjpISOeE8ebJ7TwoKkt/uVVe5MiZPTr4MUw5L3SRvy5bywPHYY5mpw/btrv/x2LHJl/Hmm+pr/+RLL3WpkHnz/CkvUXfdVf65gOsTPmCAG9nxySdd/3i/UgHr17sflkSGZCgpcecurrzSnzqkUzjF9Mwz3tc57TTXSyYVO3a4/8tMn/sKisoCfZ2qWvy13ffflz/PVOrmnXdg61Y488zkyxg40N3R/tFH4cILU6vPJ5/AlClwxRXuDveZcOONcNhhLjXSvbtLy4ikZ1tNm0KPHvD223D77d7W+fxzl2I67rj01MlPJ53k3su//Q1+85uql9+82b0XV1yR2nbr1YMTT0ytDOON5eirUFRU/vzHHzNTh9mzoUGD1L4UIjB2rMs1L16cfDnbt8Pvfw+tW7vcfKaIwDnnuFx9hw7pC/JhAwfCf/4DO3Z4W/6DD9xjv37pq5NfcnLg8svh00/dX1Vefx1KSpLLz5vM8BToRWSQiCwVkeUicmOM+e1F5E0RWSwi74hI24h5u0VkYehvtp+Vrw7hQN+sWWYCvSrMmQOnngr166dW1qhRroxHH02+jKuvhi++cCd299svtfrUJAMGuJOxH3/sbfn334dOnSAvL63V8s1vfwuNGsHkyVUvO3u2O8rp2zf99TL+qDLQi0gu8DAwGDgcGCEih0ctNgl4WlWPAiYAf4mYt11Vu4f+alwboLDQ9Vjp1SszqZuFC6G42J/WU7NmcP758Mwz7vA7UdOnuwB/ww0wZEjq9alJ+vd3Ld+33656WVXXou/fP/318st++8Ho0TBzJqxZE3+53bvhlVfc51/HEr81hpcWfR9guaquUNUSYAYwNGqZw4G3Qs/fjjG/xioqcl0HDzooMy36OXNcWsKvwDp2rOvO9txzia339ddwySUueN15pz91qUmaNIGePd35kqp88w38/HPNyM9Huuwyl5KZNi3+Mh9/DOvWpXa+KJtMn+5Sfzk57nH69EzXKD28BPo2wA8Rr4tD0yItAs4JPR8GNBaR5qHX9UVkvoj8R0TOjrUBERkTWmb+2rVrE6h++hUVuRN9eXmwejWUllbv9mfPdv2wW7b0p7xjjoFu3dzJVFVv62zdCuee684T/OMftbclF87Tx+q/H+n9991jTQv0XbrAKae4/414/+ezZ0Pduu76hJpu+nQYM8Z9x1Xd45gxwQz2fp2MvQ44QUQ+B04AVgK7Q/Paq2pvYCTwoIgcHL2yqk5V1d6q2vuAAw7wqUr+iAz0ZWWVH9b6beVKWLDA39aTCIwb5y528XLiTdVdVLNkifsCtIn+ia9FBgyAXbuqztN/8AG0aOF6stQ0l1/u/u9mzYo9f84c9z40aVKt1UqLm2/e+0d72zY3PWi8BPqVQOR1j21D0/ZQ1R9V9RxV7QHcHJq2IfS4MvS4AngH6JF6tatHSYlL17RvXx7gqjNP/89/uke/ezeMHOlOvE2ZUvWyTzwBTz8Nt97qWnu1Wf/+kJtbdZ7+gw9caz7dPYHSYcgQl8KIdVJ22TJ31XFQ0jaRXae9TE+ndKeQvAT6eUBnEekoIvsAFwAVes+ISAsRCZd1E/B4aHpTEakXXgboByzxq/Lp9sMPrkUbbtFD9ebp58yBjh3h8OhT3ylq3Nj1l545E9avj7/c4sUub3viiXDbbf7WoSZq3NhdN1BZnn7VKvj225qXtgnLzXVHcO++63pXRZozxz0GJdAfdFBi09OlOlJIVQZ6VS0FLgdeA74GnlfVr0RkgoiE25oDgKUi8g1wIDAxNL0rMF9EFuFO0t6tqjUm0Ie7VnboUP2BfutWeOMN15pPR8tw7FjXJ/zpp2PP37zZ5eX339+duM3N9b8ONdGAAS7ltXVr7Pnh/vM1qcdNtIsvdt1wo1v1s2fDkUe670M289o6njjRnXeK1KCBm55KuYmqlhRSvEtmM/WXTUMgPP64uzR8+XI33G9urrs9X3UID936xhvp28axx7qbNkdfgl5W5saRyclJfHyXoAvfUDzeiJThG5Wk80Yv1eHii924QeGbgKxbV73//8l69tmK4x2Be/3ss/GXb9/eDXHRvn3lyyVSbiJli1QsN/wn4n2/VW2sm6Tdfrt7s8NjprRp4wbIqg4XXaTapEl6A0b4zk1vvVVx+iOPaMr3Sg2qzZvd7e5uuin2/J493WBm1clrQEnE55+7/4H77ivfBqj+5z/VW49EtW8fO2i2b1+95Sbyw+BXnS3QJ2n0aNW8vPLXRx/tBnNKt9273WiC55+f3u1s2+ZGtDzvvPJpCxa4m2YPGuTtVnu10bHHupEyo4VvNHLbbdVXl2Raml4dd5z7PzzoIFduTk78QfHSWY9E+NU6TrXcRIK3X++dBfokDRzovtRhZ5/t7o2abh9/7D6Z6dPTv60//MG1UFetUv3lF9VOndxtCteuTf+2a6o//cmlMaLv5fraa+5ze/316qtLulqwqu4evdHlprtVmqpsadEn+sPgx9FQZYHeBjWrRGFhxRNPeXnVczJ2zhx38nPw4PRv65JL3MUxjz0GF13kupbNnOn6gZvYBgxwQwGET7yG+XmjEa8n/pLpIui17NkxRqaKd5Iw3V0V03WC1atEy020R09+vos3ZWXuMT8/2ZrGEe8XIFN/2dKiLy11Ld0bbyyfFr4l3/bt6d32r36V/A2lk3HSSS5dA6qTJlXfdmuqLVvcTU2i73E6cKDL0acqnfndRMpOpFWaTD28tmDTdYI1Uemssx+w1E3ifvjBvTtTppRPe+IJN+3bb9O33RUr3Dbuvz9924j2wgtum0OH2k0gvOrXT7VPn/LXO3e63jZXXZV62enM7yZSdrrqkc46Z5PqPjltgT4JH3zg3p25c8unhXOw77+fvu3+9a9uG8uWpW8b0XbvdsF+48bq22ZNd8st7uRku3bui9yqlfvcXngh/jrp6m6XSEBJpOx0taTTne+urSzQJ2H6dPfufPVV+bQvvnDTZs5M33ZPPlm1a9f0lW8q5zVY3Xhj7OAT7/6nmehuF0s6UyxepbMHS21mgT4J4XuSbtlSPm39ek1rWmXDBndeIDr3a6pHIsG4XbvEgk8mutuluo/pks7zCrWZBfokjBmj2qJFxWllZar166ted116tjlzpvtEPvggPeWbyiUSgBJtlWaiu108mb6wKZ1XmdZmFuiTcNppqrGq0qmT6siR6dlmfr77cSktTU/52Swbvsjp7GVi6YeKsuHzDprKAr31o48jPA59tDZt0jNUcWkpzJ3rhomtbQOIJTN6XzoGmEqk7/PEiVCvXsVp9evH71edrv7dNVXa+42bCizQxxAONrECfboumvrwQ/jll+AMAZuIREfvS/SHIR0X2+TnVxzPPyfH3YIvXsDKz3f3223f3o1G2r69e20BzlSLeE39TP1lQ+pmzRp3WP3Xv+4975prVBs29L+/+bXXuouWNm3yt9yaIJvGEUk0pTBggCtz2DDv+2tMOmCpm8QUFrrHeKmbrVth0yZ/tzl7trsnaePG/pZbEyR6uXgil9snerSQaEphwAD3WFNvNGJqBwv0MYRvOBIvdQP+pm+WLnW3afP7loGZlq7xSRL5YUj3GCxDh8J++1XPuETGJMsCfQzVHejDg0edcYZ/ZWZaInn0RPPXifwwpPt2cd27w8aN0LWrP+UZkw4W6GMoKnIplP3333teOm4SPmeOCxjVfa/KdEpnyiSRHwbr7WKMBfqYiopcqiHWvVpbt3aPfrXo161zPW6C1tsm3SkTrz8M1tvFGAv0McXrWgnQsCE0aeJfoJ871wWrmpKf95p3T3fKJBHWZ9vUdhboYygsjB/owd+LpmbPdkcJPXv6U146JZJ3t5SJMdnDAn2UjRvdX2WB3q+Lpnbvhtdecydhc2rAJ5FI3t1SJsZkjzqZrkC2qazHTVheHrzzTurb+v572LwZ+vRJvazqkGjePT/fArsx2aAGtCOrl5dA36aNa9GXlaW2rYIC99ilS2rlVJdsyrsbY7yzQB8lHOgjbwoeLS/PDUL288+pbWvpUvdYUwK95d2NqZks0EcpLHSjELZsGX+ZcF/6VPP0BQXQvDm0aJFaOany2pPG8u7G1EyWo49SVORSEbH60IeFr45dudJd6JSsgoLMt+bDPWnCJ1nDPWkgdgC3vLsxNY+16KNU1oc+zK9hEBIJ9OkYfx0Sv4LVGFPzWIs+SlERdOtW+TKtWrkWfyqB/pdfYPVqb4E+0VZ3ItJ9BasxJvOsRR9h+3ZYs6byE7EAdeu6HH4qF00lciI2mRtzeG39W08aY4LPAn2EcCu2qtQNpH7RVCJdKxNpdSd69yXrSWNM8Fmgj1DZDUeihfvSJ6ugwB0ZVHX0AIm1upMZNdJ60hgTbBboI3i5WCosLy+11E1BgUv/HHKIvzfmSCbnboN+GRNsFugjFBVBbm55r5rK5OW5fP6uXclt69NP4aef/L8xh+XcjTHRLNBHKCqCdu2gjoe+SOGLpn76KfHt7NoFq1a5Qc0i+XFjDsu5G2OiWaCP4KUPfVjkRVOJWrEi/rxUuzVazt0YE8360UcoLIQTT/S2bCoXTYV73MTiR4rFrl41xkTy1KIXkUEislRElovIjdkw2JsAABeeSURBVDHmtxeRN0VksYi8IyJtI+aNEpFlob9RflbeT7t2uaDttUWfyng34UC/774Vp1uKxRiTDlUGehHJBR4GBgOHAyNE5PCoxSYBT6vqUcAE4C+hdZsBtwPHAH2A20WkqX/V909xsct/ew30zZu77pHJpG4KCtwRwbRplmIxxqSflxZ9H2C5qq5Q1RJgBjA0apnDgbdCz9+OmH8a8G9VXa+qvwD/BgalXm3/eRmeOFJOjrsFYLIt+i5drFujMaZ6eAn0bYAfIl4Xh6ZFWgScE3o+DGgsIs09rouIjBGR+SIyf+3atV7r7qtE+tCHJXPRlKoL9Icdlth6xhiTLL963VwHnCAinwMnACuB3ZWvUk5Vp6pqb1XtfcABB/hUpcSEA327dt7XSeaiqTVrYMOGzA9PbIypPbwE+pVAZPhrG5q2h6r+qKrnqGoP4ObQtA1e1s0WhYUuFVOvnvd1khnvpqbdPtAYU/N5CfTzgM4i0lFE9gEuAGZHLiAiLUQkXNZNwOOh568Bp4pI09BJ2FND07JOIn3ow9q0gY0bYetW7+tYoDfGVLcqA72qlgKX4wL018DzqvqViEwQkbNCiw0AlorIN8CBwMTQuuuBO3A/FvOACaFpWaeoyPuJ2LBk+tIXFLhulG3bVr2sMcb4wdMFU6o6F5gbNe22iOcvAi/GWfdxylv4WamsDH74AYYPT2y9yEDfubO3dcInYnPsmmRjTDWxcIMbr6akJLnUDZS36L3c8GPpUkvbGGOqlwV6EhuHPlLkeDdebvixfbvblgV6Y0x1skBPcn3oARo3hoYNXYveyw0/li1zPwIW6I0x1ckCPckHepHyi6a83PDDetwYYzLBAj0u0DdvDo0a7T2vqrx7+KIpLzf8KChwPw5eT9waY4wfLNATvw+9l7x7+KIpLzf8KChw24ketdIYY9LJAj3xA72XvHs4dTNyZNU3/AgPZmaMMdUpUIG+qAh27EhsHVXXEyZWoPeSd8/Lc9v85ZfKR6MsK7OulcaYzAhMoP/mG5f7njYtsfXWrXOt9FiB3kve3evVscXFbjsW6I0x1S0wgb5zZzj2WLjrLtdf3avKxqH3knf3eqcp63FjjMmUwAR6EZgwwV3l+ve/e1+vsq6VXm607fUm4RbojTGZEphAD3DCCTBwINx9994nUeOpqg99VXeBat3aPVbVol+6FPbfH1q29FYvY4zxS6ACPcCf/wyrV8Ojj3pbvqjI9Z9vmuSdbOvXd33wvaRuunRxRwbGGFOdAhfo+/eHk06Ce+7xNk58uMdNKgHYy52mrGulMSZTAhfowbXq16yBKVOqXjaZceijVXWnqU2b3Hy7T6wxJhMCGej79YNTT3Wt+i1bKl82mTtLRavqJuFLl7pHa9EbYzIhkIEeXKv+55/h4YfjL7N5s7vQKdVAn5fnevvsjnM7dOtxY4zJpMAG+l//GgYNgnvvdQE9lmRHrYyWl+eC/Jo1secXFECdOnDwwaltxxhjkhHYQA+uVb9uHUyeHHt+sjcciVbVRVMFBS7I162b2naMMSYZgQ70ffrA6afDpEnuhGi0yq6KTURVF01ZjxtjTCYFOtADjB8P69fDQw/tPa+oCOrVS/0ipsrGuyktdXeWskBvjMmUwAf6o4+GM8+E++6DjRsrzisqcgOU5aT4Lhx4oCsjVqD/7jvYtcsCvTEmcwIf6MG16jdsgL/+teJ0P7pWAuTmQqtWsVM31rXSGJNptSLQ9+wJQ4fC/fe7gB/mV6CH+BdNhbtW2sVSxphMqRWBHlyrfuNGePBB93rHDtf3PdUTsWHxLpoqKHDnAJIdS8cYY1JVawJ99+4wbBg88IC7SCp8lyg/W/SxUjfW48YYk2m1JtCDa9Vv2uRSOH5dLBWWl+f67O/cWXG6BXpjTKbVyXQFqtNRR8Hw4e6kbOPGbppfgT580dSqVeXpoJ9/dsHfAr0xJpNqVYse4Pbb3UBnd93lesuEA3SqYl00ZWPcGGOyQa0L9L/6FZx7rjsx27atG4PGD7EumrJAb4zJBrUu0INr1YfvAeuXWOPdFBS4O1AddJB/2zHGmETVqhx92OGHu/vKtm3rX5lNm7rhFKJTN4ce6lJExhiTKbUy0ANcf72/5YnsfdFUQQH06uXvdowxJlG1MnWTLpEXTe3c6ca5sStijTGZZoHeR5EXTS1fDmVldiLWGJN5Fuh9FNmitx43xphs4SnQi8ggEVkqIstF5MYY8w8SkbdF5HMRWSwip4emdxCR7SKyMPT3qN87kIzp091FTTk57nH6dH/KzctzffQ3by4P9Ice6k/ZxhiTrCpPxopILvAwcApQDMwTkdmquiRisVuA51V1iogcDswFOoTmfauq3f2tdvKmT4cxY2DbNve6qMi9BsjPT63syIumCgqgXTto1Ci1Mo0xJlVeWvR9gOWqukJVS4AZwNCoZRTYL/S8CRDn7qmZd/PN5UE+bNs2Nz1VkX3pbYwbY0y28BLo2wA/RLwuDk2LNB74jYgU41rzV0TM6xhK6bwrIv1TqawfwqNWep2eiOgWvQV6Y0w28Otk7AjgSVVtC5wOPCMiOcAq4CBV7QH8AXhORPaLXllExojIfBGZv3btWp+qFFu8q1T9uHo1HOjnzXO5egv0xphs4CXQrwTaRbxuG5oW6WLgeQBV/RioD7RQ1Z2qui40fQHwLbDX6UlVnaqqvVW19wEHHJD4XiRg4kRo0KDitAYN3PRUNWwITZrAW2+51xbojTHZwEugnwd0FpGOIrIPcAEwO2qZ74GTAESkKy7QrxWRA0IncxGRTkBnYIVflU9Gfj5MnerGuQmPdzN1auonYsPy8uCrr9xzC/TGmGxQZa8bVS0VkcuB14Bc4HFV/UpEJgDzVXU2cC0wTUSuwZ2YHa2qKiLHAxNEZBdQBoxV1fVp2xuP8vP9C+zR8vLg669db5vWrdOzDWOMSYSnsW5UdS7uJGvktNsini8B+sVY7yXgpRTrWKOEe9506eKOGIwxJtPsylifhU/IWtrGGJMtLND7zAK9MSbbWKD3WWTqxhhjsoEFep8dfzxccAEMHJjpmhhjjFNrbzySLi1awD/+kelaGGNMOWvRG2NMwFmgN8aYgLNAb4wxAWeB3hhjAs4CvTHGBJwFemOMCTgL9MYYE3AW6I0xJuAs0BtjTMBZoDfGmICzQG+MMQFngd4YYwLOAr0xxgScBXpjjAk4C/TGGBNwFuiNMSbgLNAbY0zAWaA3xpiAs0BvjDEBZ4HeGGMCzgK9McYEnAV6Y4wJOAv0xhgTcBbojTEm4CzQG2NMwFmgN8aYgLNAb4wxAWeB3hhjAs4CvTHGBJwFemOMCTgL9MYYE3AW6I0xJuA8BXoRGSQiS0VkuYjcGGP+QSLytoh8LiKLReT0iHk3hdZbKiKn+Vl5Y4wxVatT1QIikgs8DJwCFAPzRGS2qi6JWOwW4HlVnSIihwNzgQ6h5xcARwB5wBsicqiq7vZ7R4wxxsTmpUXfB1iuqitUtQSYAQyNWkaB/ULPmwA/hp4PBWao6k5V/Q5YHirPGGNMNfES6NsAP0S8Lg5NizQe+I2IFONa81cksC4iMkZE5ovI/LVr13qsujHGGC/8Ohk7AnhSVdsCpwPPiIjnslV1qqr2VtXeBxxwgE9VMsYYAx5y9MBKoF3E67ahaZEuBgYBqOrHIlIfaOFxXWOMMWnkJdDPAzqLSEdckL4AGBm1zPfAScCTItIVqA+sBWYDz4nI/biTsZ2BT32quzHGZ7t27aK4uJgdO3Zkuiomjvr169O2bVvq1q3reZ0qA72qlorI5cBrQC7wuKp+JSITgPmqOhu4FpgmItfgTsyOVlUFvhKR54ElQClwmfW4MSZ7FRcX07hxYzp06ICIZLo6Joqqsm7dOoqLi+nYsaPn9by06FHVubiTrJHTbot4vgToF2fdicBEzzUyxmTMjh07LMhnMRGhefPmJNppxa6MNcZUYEE+uyXz+VigN8aYgLNAb4xJ2vTp0KED5OS4x+nTUytv3bp1dO/ene7du9OqVSvatGmz53VJSUml686fP58rr7yyym307ds3tUrWQJ5y9MYYE236dBgzBrZtc6+LitxrgPz85Mps3rw5CxcuBGD8+PE0atSI6667bs/80tJS6tSJHbZ69+5N7969q9zGRx99lFzlajBr0RtjknLzzeVBPmzbNjfdT6NHj2bs2LEcc8wxXH/99Xz66acce+yx9OjRg759+7J06VIA3nnnHc444wzA/UhcdNFFDBgwgE6dOvHQQw/tKa9Ro0Z7lh8wYADDhw+nS5cu5Ofn4zoLwty5c+nSpQu9evXiyiuv3FNupMLCQvr370/Pnj3p2bNnhR+Qe+65hyOPPJJu3bpx441uHMjly5dz8skn061bN3r27Mm3337r7xtVCWvRG2OS8v33iU1PRXFxMR999BG5ubls2rSJ999/nzp16vDGG2/wpz/9iZdeemmvdQoKCnj77bfZvHkzhx12GOPGjdur7/nnn3/OV199RV5eHv369ePDDz+kd+/eXHLJJbz33nt07NiRESNGxKxTy5Yt+fe//039+vVZtmwZI0aMYP78+bz66qu8/PLLfPLJJzRo0ID169cDkJ+fz4033siwYcPYsWMHZWVl/r9RcVigN8Yk5aCDXLom1nS/nXvuueTm5gKwceNGRo0axbJlyxARdu3aFXOdIUOGUK9ePerVq0fLli1ZvXo1bdu2rbBMnz599kzr3r07hYWFNGrUiE6dOu3ppz5ixAimTp26V/m7du3i8ssvZ+HCheTm5vLNN98A8MYbb/C73/2OBg0aANCsWTM2b97MypUrGTZsGOAueqpOlroxxiRl4kQIxbI9GjRw0/3WsGHDPc9vvfVWBg4cyJdffsmcOXPiXsVbr169Pc9zc3MpLS1Napl4HnjgAQ488EAWLVrE/PnzqzxZnEkW6I0xScnPh6lToX17EHGPU6cmfyLWq40bN9KmjRsE98knn/S9/MMOO4wVK1ZQWFgIwMyZM+PWo3Xr1uTk5PDMM8+we7e76P+UU07hiSeeYFvoBMb69etp3Lgxbdu2ZdasWQDs3Llzz/zqYIHeGJO0/HwoLISyMveY7iAPcP3113PTTTfRo0ePhFrgXu2777488sgjDBo0iF69etG4cWOaNGmy13KXXnopTz31FN26daOgoGDPUcegQYM466yz6N27N927d2fSpEkAPPPMMzz00EMcddRR9O3bl59++sn3uscj4bPM2aJ37946f/78TFfDmFrp66+/pmvXrpmuRsZt2bKFRo0aoapcdtlldO7cmWuuuSbT1doj1uckIgtUNWb/UmvRG2NMlGnTptG9e3eOOOIINm7cyCWXXJLpKqXEet0YY0yUa665Jqta8KmyFr0xxgScBXpjjAk4C/TGGBNwFuiNMSbgLNAbY7LGwIEDee211ypMe/DBBxk3blzcdQYMGEC4S/bpp5/Ohg0b9lpm/Pjxe/qzxzNr1iyWLFmy5/Vtt93GG2+8kUj1s5YFemNM1hgxYgQzZsyoMG3GjBlxBxaLNnfuXPbff/+kth0d6CdMmMDJJ5+cVFnZxrpXGmNiuvpqCA0N75vu3eHBB+PPHz58OLfccgslJSXss88+FBYW8uOPP9K/f3/GjRvHvHnz2L59O8OHD+fPf/7zXut36NCB+fPn06JFCyZOnMhTTz1Fy5YtadeuHb169QJcH/mpU6dSUlLCIYccwjPPPMPChQuZPXs27777LnfeeScvvfQSd9xxB2eccQbDhw/nzTff5LrrrqO0tJSjjz6aKVOmUK9ePTp06MCoUaOYM2cOu3bt4oUXXqBLly4V6lRYWMiFF17I1q1bAZg8efKem5/cc889PPvss+Tk5DB48GDuvvtuli9fztixY1m7di25ubm88MILHHzwwSm979aiN8ZkjWbNmtGnTx9effVVwLXmzzvvPESEiRMnMn/+fBYvXsy7777L4sWL45azYMECZsyYwcKFC5k7dy7z5s3bM++cc85h3rx5LFq0iK5du/LYY4/Rt29fzjrrLO69914WLlxYIbDu2LGD0aNHM3PmTL744gtKS0uZMmXKnvktWrTgs88+Y9y4cTHTQ+HhjD/77DNmzpy55y5YkcMZL1q0iOuvvx5wwxlfdtllLFq0iI8++ojWrVun9qZiLXpjTByVtbzTKZy+GTp0KDNmzOCxxx4D4Pnnn2fq1KmUlpayatUqlixZwlFHHRWzjPfff59hw4btGSr4rLPO2jPvyy+/5JZbbmHDhg1s2bKF0047rdL6LF26lI4dO3LooYcCMGrUKB5++GGuvvpqwP1wAPTq1Yv//d//3Wv9bBjOODAter/vXWmMyYyhQ4fy5ptv8tlnn7Ft2zZ69erFd999x6RJk3jzzTdZvHgxQ4YMiTs8cVVGjx7N5MmT+eKLL7j99tuTLicsPNRxvGGOs2E440AE+vC9K4uKQLX83pUW7I2peRo1asTAgQO56KKL9pyE3bRpEw0bNqRJkyasXr16T2onnuOPP55Zs2axfft2Nm/ezJw5c/bM27x5M61bt2bXrl1MjwgSjRs3ZvPmzXuVddhhh1FYWMjy5csBNwrlCSec4Hl/smE440AE+uq6d6UxpnqMGDGCRYsW7Qn03bp1o0ePHnTp0oWRI0fSr1+/Stfv2bMn559/Pt26dWPw4MEcffTRe+bdcccdHHPMMfTr16/CidMLLriAe++9lx49elS4n2v9+vV54oknOPfccznyyCPJyclh7NixnvclG4YzDsQwxTk5riUfTcSNk22M8caGKa4ZauUwxfHuUZmOe1caY0xNE4hAX533rjTGmJomEIE+U/euNCaIsi2daypK5vMJTD/6/HwL7Makqn79+qxbt47mzZsjIpmujomiqqxbty7h/vWBCfTGmNS1bduW4uJi1q5dm+mqmDjq169P27ZtE1rHAr0xZo+6devSsWPHTFfD+CwQOXpjjDHxWaA3xpiAs0BvjDEBl3VXxorIWqAoYlIL4OcMVae6BH0fbf9qvqDvYxD2r72qHhBrRtYF+mgiMj/eZb1BEfR9tP2r+YK+j0HfP0vdGGNMwFmgN8aYgKsJgX5qpitQDYK+j7Z/NV/Q9zHQ+5f1OXpjjDGpqQktemOMMSmwQG+MMQGX1YFeRAaJyFIRWS4iN2a6Pn4TkUIR+UJEFopIYrfVylIi8riIrBGRLyOmNRORf4vIstBj00zWMRVx9m+8iKwMfY4LReT0TNYxFSLSTkTeFpElIvKViFwVmh6kzzDePgbmc4yWtTl6EckFvgFOAYqBecAIVV2S0Yr5SEQKgd6qWtMv1NhDRI4HtgBPq+qvQtP+B1ivqneHfrCbquoNmaxnsuLs33hgi6pOymTd/CAirYHWqvqZiDQGFgBnA6MJzmcYbx/PIyCfY7RsbtH3AZar6gpVLQFmAEMzXCdTBVV9D1gfNXko8FTo+VO4L1WNFGf/AkNVV6nqZ6Hnm4GvgTYE6zOMt4+Blc2Bvg3wQ8TrYoL3YSjwuogsEJExma5MGh2oqqtCz38CDsxkZdLkchFZHErt1Ni0RiQR6QD0AD4hoJ9h1D5CAD9HyO5AXxscp6o9gcHAZaG0QKCpyxVmZ74weVOAg4HuwCrgvsxWJ3Ui0gh4CbhaVTdFzgvKZxhjHwP3OYZlc6BfCbSLeN02NC0wVHVl6HEN8H+4dFUQrQ7lRcP50TUZro+vVHW1qu5W1TJgGjX8cxSRurgAOF1V/zc0OVCfYax9DNrnGCmbA/08oLOIdBSRfYALgNkZrpNvRKRh6EQQItIQOBX4svK1aqzZwKjQ81HAyxmsi+/CATBkGDX4cxR3o9jHgK9V9f6IWYH5DOPtY5A+x2hZ2+sGINS96UEgF3hcVSdmuEq+EZFOuFY8uFs6PheE/RORfwADcMO+rgZuB2YBzwMH4YagPk9Va+QJzTj7NwB3uK9AIXBJRD67RhGR44D3gS+AstDkP+Fy2EH5DOPt4wgC8jlGy+pAb4wxJnXZnLoxxhjjAwv0xhgTcBbojTEm4CzQG2NMwFmgN8aYgLNAb4wxAWeB3hhjAu7/A12en8CQ58FrAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kSiv_KMUFO0"
      },
      "source": [
        "#model.save('/root/data/ReducedInputSizeModel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uxovqcs4JOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf6d845-7a20-4bac-a2fc-9a4f31834a5a"
      },
      "source": [
        "Y_pred = model.predict(val_set_cm,878) # ceil(num_of_test_samples / batch_size)\n",
        "Y_pred = (Y_pred>0.5)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(val_set_cm.classes, Y_pred))\n",
        "print('Classification Report')\n",
        "target_names = ['PlaceHolder', 'PlaceHolder']\n",
        "print(classification_report(val_set_cm.classes, Y_pred, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[234   4]\n",
            " [ 24 616]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " PlaceHolder       0.91      0.98      0.94       238\n",
            " PlaceHolder       0.99      0.96      0.98       640\n",
            "\n",
            "    accuracy                           0.97       878\n",
            "   macro avg       0.95      0.97      0.96       878\n",
            "weighted avg       0.97      0.97      0.97       878\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbMk8XqK15KS"
      },
      "source": [
        "# Grad-CAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X4arQRgwJQ-"
      },
      "source": [
        "img_path = 'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet/test/PNEUMONIA/person69_bacteria_338.jpeg'\n",
        "\n",
        "img = image.load_img(img_path, target_size=(75,75))\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "x = x/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "intdWr1iwWir"
      },
      "source": [
        "#Taken from https://keras.io/examples/vision/grad_cam/\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer as well as the output predictions\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # This is the gradient of the output neuron (top predicted or chosen)\n",
        "    # with regard to the output feature map of the last conv layer\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    # then sum all the channels to obtain the heatmap class activation\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChJfnYNywZx0"
      },
      "source": [
        "# Generate class activation heatmap\n",
        "#heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "heatmap = make_gradcam_heatmap(x, model, 'conv2d_7')\n",
        "\n",
        "# Display heatmap\n",
        "plt.matshow(heatmap)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRkc7lA_wb7i"
      },
      "source": [
        "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
        "    # Load the original image\n",
        "    img = keras.preprocessing.image.load_img(img_path)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Use jet colormap to colorize heatmap\n",
        "    jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "    # Use RGB values of the colormap\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    # Create an image with RGB colorized heatmap\n",
        "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Superimpose the heatmap on original image\n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "    # Save the superimposed image\n",
        "    superimposed_img.save(cam_path)\n",
        "\n",
        "    # Display Grad CAM\n",
        "    display(Image(cam_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdfRf-S3wfLA"
      },
      "source": [
        "save_and_display_gradcam(img_path, heatmap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6X4OUo5009g"
      },
      "source": [
        "# K-fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFI-wzHF3Wt3"
      },
      "source": [
        "#Adapted from https://github.com/SadmanSakib93/Stratified-k-fold-cross-validation-Image-classification-keras\n",
        "\n",
        "#Create folder for val partition of the training splits\n",
        "!mkdir /root/data/DataSet/val_train_fold\n",
        "!mkdir /root/data/DataSet/val_train_fold/NORMAL\n",
        "!mkdir /root/data/DataSet/val_train_fold/PNEUMONIA\n",
        "\n",
        "datasetFolderName='/root/data/DataSet'\n",
        "sourceFiles=[]\n",
        "classLabels=['NORMAL', 'PNEUMONIA']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM9GnW0AOHpa"
      },
      "source": [
        "#Adapted from https://github.com/SadmanSakib93/Stratified-k-fold-cross-validation-Image-classification-keras\n",
        "\n",
        "def transferBetweenFolders(source, dest, splitRate):   \n",
        "    global sourceFiles\n",
        "    sourceFiles=os.listdir(source)\n",
        "    if(len(sourceFiles)!=0):\n",
        "        transferFileNumbers=int(len(sourceFiles)*splitRate)\n",
        "        transferIndex=random.sample(range(0, len(sourceFiles)), transferFileNumbers)\n",
        "        for eachIndex in transferIndex:\n",
        "            shutil.move(source+str(sourceFiles[eachIndex]), dest+str(sourceFiles[eachIndex]))\n",
        "    else:\n",
        "        print(\"No file moved. Source empty!\")\n",
        "        \n",
        "def transferAllClassBetweenFolders(source, dest, splitRate):\n",
        "    for label in classLabels:\n",
        "        transferBetweenFolders(datasetFolderName+'/'+source+'/'+label+'/', \n",
        "                               datasetFolderName+'/'+dest+'/'+label+'/', \n",
        "                               splitRate)\n",
        "        \n",
        "def my_metrics(y_true, y_pred):\n",
        "    accuracy=accuracy_score(y_true, y_pred)\n",
        "    precision=precision_score(y_true, y_pred)\n",
        "    recall=recall_score(y_true, y_pred)\n",
        "    f1Score=f1_score(y_true, y_pred) \n",
        "    print(\"Accuracy  : {}\".format(accuracy))\n",
        "    print(\"Precision : {}\".format(precision))\n",
        "    print(\"Recall : {}\".format(recall))\n",
        "    print(\"f1Score : {}\".format(f1Score))\n",
        "    cm=confusion_matrix(y_true, y_pred)\n",
        "    print(cm)\n",
        "    return accuracy, precision, recall, f1Score"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCxHvFkR57_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d7ff822-8a7d-4016-8f5a-ef3cbb6d499d"
      },
      "source": [
        "#Adapted from https://github.com/SadmanSakib93/Stratified-k-fold-cross-validation-Image-classification-keras\n",
        "\n",
        "X=[]\n",
        "Y=[]\n",
        "\n",
        "def prepareNameWithLabels(folderName):\n",
        "    sourceFiles=os.listdir(datasetFolderName+'/train/'+folderName)\n",
        "    for val in sourceFiles:\n",
        "        X.append(val)\n",
        "        if(folderName==classLabels[0]):\n",
        "            Y.append(0)\n",
        "        elif(folderName==classLabels[1]):\n",
        "            Y.append(1)\n",
        "       \n",
        "# Organize file names and class labels in X and Y variables\n",
        "prepareNameWithLabels(classLabels[0])\n",
        "prepareNameWithLabels(classLabels[1])\n",
        "      \n",
        "X=np.asarray(X)\n",
        "Y=np.asarray(Y)\n",
        "\n",
        "# learning rate\n",
        "batch_size = 20\n",
        "epochs=25\n",
        "activationFunction='relu'\n",
        "\n",
        "def getModel():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(75,75,3)))\n",
        "    model.add(layers.MaxPooling2D((2,2), strides=2))\n",
        "    model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2,2), strides=2))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols =  75, 75\n",
        "\n",
        "train_path=datasetFolderName+'/train/'\n",
        "validation_path=datasetFolderName+'/val_train_fold/'\n",
        "model=getModel()\n",
        "acc_avg=[]\n",
        "prec_avg=[]\n",
        "rec_avg=[]\n",
        "f1_agv=[]\n",
        "# ===============Stratified K-Fold======================\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True)\n",
        "skf.get_n_splits(X, Y)\n",
        "foldNum=0\n",
        "for train_index, val_index in skf.split(X, Y):\n",
        "    #First cut all images from validation to train (if any exists)\n",
        "    transferAllClassBetweenFolders('val_train_fold', 'train', 1.0)\n",
        "    foldNum+=1\n",
        "    print(\"Results for fold\",foldNum)\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
        "    # Move validation images of this fold from train folder to the validation folder\n",
        "    for eachIndex in range(len(X_val)):\n",
        "        classLabel=''\n",
        "        if(Y_val[eachIndex]==0):\n",
        "            classLabel=classLabels[0]\n",
        "        elif(Y_val[eachIndex]==1):\n",
        "            classLabel=classLabels[1]\n",
        " \n",
        "        #Then, copy the validation images to the validation folder\n",
        "        shutil.move(datasetFolderName+'/train/'+classLabel+'/'+X_val[eachIndex], \n",
        "                    datasetFolderName+'/val_train_fold/'+classLabel+'/'+X_val[eachIndex])\n",
        "        \n",
        "    train_datagen_kf = ImageDataGenerator(\n",
        "                       rescale=1./255,\n",
        "                       )\n",
        "    validation_datagen_kf = ImageDataGenerator(rescale=1./255)\n",
        "        \n",
        "    #Start ImageClassification Model\n",
        "    train_generator_kf = train_datagen_kf.flow_from_directory(\n",
        "                          train_path,\n",
        "                          target_size=(img_rows, img_cols),\n",
        "                          batch_size=batch_size,\n",
        "                          class_mode='binary'\n",
        "                          )\n",
        "\n",
        "    validation_generator_kf = validation_datagen_kf.flow_from_directory(\n",
        "                              validation_path,\n",
        "                              target_size=(img_rows, img_cols),\n",
        "                              batch_size=batch_size,\n",
        "                              class_mode='binary' \n",
        "                              )  \n",
        "    \n",
        "    validation_generator_2 = validation_datagen_kf.flow_from_directory(\n",
        "                             validation_path,\n",
        "                             target_size=(img_rows, img_cols),\n",
        "                             batch_size=1,\n",
        "                             class_mode='binary',  # only data, no labels\n",
        "                             shuffle=False)   \n",
        "    \n",
        "    # fit model\n",
        "    callbacks_list= [keras.callbacks.EarlyStopping(monitor = 'acc', patience=5), \n",
        "                     keras.callbacks.ModelCheckpoint(filepath=\"/root/data/DataSet/my_model.h5\", \n",
        "                                                      monitor =\"val_loss\", save_best_only=True)]\n",
        "    model=getModel()\n",
        "\n",
        "    history= model.fit(\n",
        "        train_generator_kf,\n",
        "        epochs= epochs,\n",
        "        steps_per_epoch=len(train_index)//batch_size,\n",
        "        validation_data=validation_generator_kf,\n",
        "        validation_steps=len(val_index)//batch_size, \n",
        "        callbacks=callbacks_list\n",
        "        )\n",
        "    \n",
        "    predictions = model.predict(validation_generator_2,len(val_index)) # ceil(num_of_test_samples / batch_size)\n",
        "    yPredictions = (predictions>0.5)\n",
        "    true_classes = validation_generator_2.classes\n",
        "    # evaluate validation performance\n",
        "    print(\"***Performance on Validation data***\")    \n",
        "    valAcc, valPrec, valRec, valFScore = my_metrics(true_classes, yPredictions)\n",
        "    acc_avg.append(valAcc)\n",
        "    prec_avg.append(valPrec)\n",
        "    rec_avg.append(valRec)\n",
        "    f1_agv.append(valFScore)\n",
        "\n",
        "#Place all of the training data back to the training folder\n",
        "transferAllClassBetweenFolders('val_train_fold', 'train', 1.0)\n",
        "\n",
        "#Delete folders we no longer need\n",
        "!rm -rf /root/data/DataSet/val_train_fold/PNEUMONIA\n",
        "!rm -rf /root/data/DataSet/val_train_fold/NORMAL\n",
        "!rm -rf /root/data/DataSet/val_train_fold"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n",
            "Results for fold 1\n",
            "Found 2734 images belonging to 2 classes.\n",
            "Found 1367 images belonging to 2 classes.\n",
            "Found 1367 images belonging to 2 classes.\n",
            "Epoch 1/25\n",
            "136/136 [==============================] - 76s 547ms/step - loss: 0.5901 - acc: 0.7399 - val_loss: 0.3529 - val_acc: 0.8184\n",
            "Epoch 2/25\n",
            "136/136 [==============================] - 74s 544ms/step - loss: 0.3432 - acc: 0.8563 - val_loss: 0.2858 - val_acc: 0.9140\n",
            "Epoch 3/25\n",
            "136/136 [==============================] - 72s 530ms/step - loss: 0.2737 - acc: 0.8892 - val_loss: 0.1933 - val_acc: 0.9301\n",
            "Epoch 4/25\n",
            "136/136 [==============================] - 72s 527ms/step - loss: 0.2223 - acc: 0.9168 - val_loss: 0.1703 - val_acc: 0.9346\n",
            "Epoch 5/25\n",
            "136/136 [==============================] - 73s 533ms/step - loss: 0.2059 - acc: 0.9211 - val_loss: 0.2168 - val_acc: 0.9206\n",
            "Epoch 6/25\n",
            "136/136 [==============================] - 72s 527ms/step - loss: 0.1755 - acc: 0.9353 - val_loss: 0.1524 - val_acc: 0.9382\n",
            "Epoch 7/25\n",
            "136/136 [==============================] - 71s 518ms/step - loss: 0.1764 - acc: 0.9304 - val_loss: 0.1409 - val_acc: 0.9434\n",
            "Epoch 8/25\n",
            "136/136 [==============================] - 67s 496ms/step - loss: 0.1466 - acc: 0.9406 - val_loss: 0.1381 - val_acc: 0.9463\n",
            "Epoch 9/25\n",
            "136/136 [==============================] - 68s 500ms/step - loss: 0.1598 - acc: 0.9430 - val_loss: 0.1436 - val_acc: 0.9404\n",
            "Epoch 10/25\n",
            "136/136 [==============================] - 67s 496ms/step - loss: 0.1621 - acc: 0.9360 - val_loss: 0.1285 - val_acc: 0.9515\n",
            "Epoch 11/25\n",
            "136/136 [==============================] - 67s 495ms/step - loss: 0.1291 - acc: 0.9503 - val_loss: 0.1334 - val_acc: 0.9434\n",
            "Epoch 12/25\n",
            "136/136 [==============================] - 68s 497ms/step - loss: 0.1418 - acc: 0.9418 - val_loss: 0.1402 - val_acc: 0.9375\n",
            "Epoch 13/25\n",
            "136/136 [==============================] - 68s 500ms/step - loss: 0.1366 - acc: 0.9478 - val_loss: 0.1282 - val_acc: 0.9507\n",
            "Epoch 14/25\n",
            "136/136 [==============================] - 69s 505ms/step - loss: 0.1397 - acc: 0.9457 - val_loss: 0.1192 - val_acc: 0.9544\n",
            "Epoch 15/25\n",
            "136/136 [==============================] - 68s 502ms/step - loss: 0.1258 - acc: 0.9501 - val_loss: 0.1195 - val_acc: 0.9529\n",
            "Epoch 16/25\n",
            "136/136 [==============================] - 70s 514ms/step - loss: 0.1220 - acc: 0.9546 - val_loss: 0.1248 - val_acc: 0.9471\n",
            "Epoch 17/25\n",
            "136/136 [==============================] - 68s 503ms/step - loss: 0.1080 - acc: 0.9601 - val_loss: 0.1253 - val_acc: 0.9500\n",
            "Epoch 18/25\n",
            "136/136 [==============================] - 69s 505ms/step - loss: 0.1200 - acc: 0.9596 - val_loss: 0.1159 - val_acc: 0.9522\n",
            "Epoch 19/25\n",
            "136/136 [==============================] - 68s 502ms/step - loss: 0.1115 - acc: 0.9619 - val_loss: 0.1148 - val_acc: 0.9566\n",
            "Epoch 20/25\n",
            "136/136 [==============================] - 68s 497ms/step - loss: 0.0980 - acc: 0.9623 - val_loss: 0.1331 - val_acc: 0.9463\n",
            "Epoch 21/25\n",
            "136/136 [==============================] - 67s 492ms/step - loss: 0.1110 - acc: 0.9614 - val_loss: 0.1081 - val_acc: 0.9551\n",
            "Epoch 22/25\n",
            "136/136 [==============================] - 67s 492ms/step - loss: 0.1166 - acc: 0.9638 - val_loss: 0.1125 - val_acc: 0.9522\n",
            "Epoch 23/25\n",
            "136/136 [==============================] - 67s 490ms/step - loss: 0.0966 - acc: 0.9652 - val_loss: 0.1072 - val_acc: 0.9574\n",
            "Epoch 24/25\n",
            "136/136 [==============================] - 67s 491ms/step - loss: 0.0927 - acc: 0.9635 - val_loss: 0.1152 - val_acc: 0.9500\n",
            "Epoch 25/25\n",
            "136/136 [==============================] - 70s 515ms/step - loss: 0.0819 - acc: 0.9674 - val_loss: 0.1029 - val_acc: 0.9566\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.9561082662765179\n",
            "Precision : 0.9558214115684135\n",
            "f1Score : 0.9558380767738983\n",
            "[[333  37]\n",
            " [ 23 974]]\n",
            "Results for fold 2\n",
            "Found 2734 images belonging to 2 classes.\n",
            "Found 1367 images belonging to 2 classes.\n",
            "Found 1367 images belonging to 2 classes.\n",
            "Epoch 1/25\n",
            "136/136 [==============================] - 69s 500ms/step - loss: 0.5363 - acc: 0.7396 - val_loss: 0.3309 - val_acc: 0.9015\n",
            "Epoch 2/25\n",
            "136/136 [==============================] - 67s 493ms/step - loss: 0.3241 - acc: 0.8659 - val_loss: 0.2474 - val_acc: 0.8941\n",
            "Epoch 3/25\n",
            "136/136 [==============================] - 69s 509ms/step - loss: 0.2128 - acc: 0.9152 - val_loss: 0.1945 - val_acc: 0.9287\n",
            "Epoch 4/25\n",
            "136/136 [==============================] - 67s 496ms/step - loss: 0.1859 - acc: 0.9255 - val_loss: 0.2529 - val_acc: 0.8897\n",
            "Epoch 5/25\n",
            "136/136 [==============================] - 68s 497ms/step - loss: 0.1831 - acc: 0.9247 - val_loss: 0.2475 - val_acc: 0.9022\n",
            "Epoch 6/25\n",
            "136/136 [==============================] - 67s 496ms/step - loss: 0.1670 - acc: 0.9392 - val_loss: 0.1589 - val_acc: 0.9404\n",
            "Epoch 7/25\n",
            "136/136 [==============================] - 67s 493ms/step - loss: 0.1580 - acc: 0.9326 - val_loss: 0.1506 - val_acc: 0.9449\n",
            "Epoch 8/25\n",
            "136/136 [==============================] - 70s 515ms/step - loss: 0.1611 - acc: 0.9359 - val_loss: 0.1746 - val_acc: 0.9346\n",
            "Epoch 9/25\n",
            "136/136 [==============================] - 67s 496ms/step - loss: 0.1229 - acc: 0.9524 - val_loss: 0.1535 - val_acc: 0.9456\n",
            "Epoch 10/25\n",
            "136/136 [==============================] - 67s 492ms/step - loss: 0.1314 - acc: 0.9481 - val_loss: 0.1706 - val_acc: 0.9419\n",
            "Epoch 11/25\n",
            "136/136 [==============================] - 67s 496ms/step - loss: 0.1205 - acc: 0.9543 - val_loss: 0.1648 - val_acc: 0.9419\n",
            "Epoch 12/25\n",
            "136/136 [==============================] - 67s 492ms/step - loss: 0.1152 - acc: 0.9561 - val_loss: 0.1436 - val_acc: 0.9500\n",
            "Epoch 13/25\n",
            "136/136 [==============================] - 67s 491ms/step - loss: 0.1060 - acc: 0.9625 - val_loss: 0.1453 - val_acc: 0.9456\n",
            "Epoch 14/25\n",
            "136/136 [==============================] - 66s 487ms/step - loss: 0.0979 - acc: 0.9660 - val_loss: 0.1596 - val_acc: 0.9463\n",
            "Epoch 15/25\n",
            "136/136 [==============================] - 67s 491ms/step - loss: 0.1056 - acc: 0.9622 - val_loss: 0.1498 - val_acc: 0.9471\n",
            "Epoch 16/25\n",
            "136/136 [==============================] - 67s 491ms/step - loss: 0.1198 - acc: 0.9572 - val_loss: 0.1466 - val_acc: 0.9456\n",
            "Epoch 17/25\n",
            "136/136 [==============================] - 67s 489ms/step - loss: 0.0896 - acc: 0.9668 - val_loss: 0.1514 - val_acc: 0.9478\n",
            "Epoch 18/25\n",
            "136/136 [==============================] - 67s 493ms/step - loss: 0.0906 - acc: 0.9673 - val_loss: 0.1655 - val_acc: 0.9412\n",
            "Epoch 19/25\n",
            "136/136 [==============================] - 67s 494ms/step - loss: 0.0963 - acc: 0.9648 - val_loss: 0.1500 - val_acc: 0.9456\n",
            "Epoch 20/25\n",
            "136/136 [==============================] - 67s 492ms/step - loss: 0.0934 - acc: 0.9692 - val_loss: 0.1359 - val_acc: 0.9522\n",
            "Epoch 21/25\n",
            "136/136 [==============================] - 67s 490ms/step - loss: 0.0930 - acc: 0.9688 - val_loss: 0.1531 - val_acc: 0.9493\n",
            "Epoch 22/25\n",
            "136/136 [==============================] - 67s 493ms/step - loss: 0.0713 - acc: 0.9764 - val_loss: 0.1476 - val_acc: 0.9471\n",
            "Epoch 23/25\n",
            "136/136 [==============================] - 67s 494ms/step - loss: 0.0812 - acc: 0.9711 - val_loss: 0.1455 - val_acc: 0.9493\n",
            "Epoch 24/25\n",
            "136/136 [==============================] - 67s 496ms/step - loss: 0.0764 - acc: 0.9717 - val_loss: 0.1453 - val_acc: 0.9507\n",
            "Epoch 25/25\n",
            "136/136 [==============================] - 67s 497ms/step - loss: 0.0790 - acc: 0.9727 - val_loss: 0.1425 - val_acc: 0.9522\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.9524506217995611\n",
            "Precision : 0.9521089817591942\n",
            "f1Score : 0.9521347058150581\n",
            "[[329  40]\n",
            " [ 25 973]]\n",
            "Results for fold 3\n",
            "Found 2734 images belonging to 2 classes.\n",
            "Found 1367 images belonging to 2 classes.\n",
            "Found 1367 images belonging to 2 classes.\n",
            "Epoch 1/25\n",
            "136/136 [==============================] - 69s 502ms/step - loss: 0.5441 - acc: 0.7517 - val_loss: 0.3582 - val_acc: 0.9074\n",
            "Epoch 2/25\n",
            "136/136 [==============================] - 70s 513ms/step - loss: 0.3046 - acc: 0.8805 - val_loss: 0.4059 - val_acc: 0.8243\n",
            "Epoch 3/25\n",
            "136/136 [==============================] - 69s 506ms/step - loss: 0.2469 - acc: 0.8986 - val_loss: 0.2570 - val_acc: 0.8838\n",
            "Epoch 4/25\n",
            "136/136 [==============================] - 68s 497ms/step - loss: 0.1911 - acc: 0.9264 - val_loss: 0.1748 - val_acc: 0.9316\n",
            "Epoch 5/25\n",
            "136/136 [==============================] - 68s 498ms/step - loss: 0.1801 - acc: 0.9303 - val_loss: 0.1634 - val_acc: 0.9346\n",
            "Epoch 6/25\n",
            "136/136 [==============================] - 67s 493ms/step - loss: 0.1647 - acc: 0.9339 - val_loss: 0.2138 - val_acc: 0.9132\n",
            "Epoch 7/25\n",
            "136/136 [==============================] - 67s 494ms/step - loss: 0.1489 - acc: 0.9459 - val_loss: 0.1720 - val_acc: 0.9353\n",
            "Epoch 8/25\n",
            "136/136 [==============================] - 67s 490ms/step - loss: 0.1385 - acc: 0.9449 - val_loss: 0.2759 - val_acc: 0.8963\n",
            "Epoch 9/25\n",
            "136/136 [==============================] - 67s 492ms/step - loss: 0.1283 - acc: 0.9510 - val_loss: 0.1526 - val_acc: 0.9375\n",
            "Epoch 10/25\n",
            "136/136 [==============================] - 68s 503ms/step - loss: 0.1193 - acc: 0.9560 - val_loss: 0.1504 - val_acc: 0.9360\n",
            "Epoch 11/25\n",
            "136/136 [==============================] - 67s 493ms/step - loss: 0.1316 - acc: 0.9485 - val_loss: 0.1510 - val_acc: 0.9390\n",
            "Epoch 12/25\n",
            "136/136 [==============================] - 67s 492ms/step - loss: 0.1209 - acc: 0.9553 - val_loss: 0.1720 - val_acc: 0.9346\n",
            "Epoch 13/25\n",
            "136/136 [==============================] - 67s 489ms/step - loss: 0.1089 - acc: 0.9569 - val_loss: 0.1702 - val_acc: 0.9368\n",
            "Epoch 14/25\n",
            "136/136 [==============================] - 67s 491ms/step - loss: 0.1117 - acc: 0.9577 - val_loss: 0.1768 - val_acc: 0.9368\n",
            "Epoch 15/25\n",
            "136/136 [==============================] - 67s 490ms/step - loss: 0.1102 - acc: 0.9541 - val_loss: 0.1472 - val_acc: 0.9397\n",
            "Epoch 16/25\n",
            "136/136 [==============================] - 67s 491ms/step - loss: 0.1186 - acc: 0.9564 - val_loss: 0.1477 - val_acc: 0.9419\n",
            "Epoch 17/25\n",
            "136/136 [==============================] - 67s 492ms/step - loss: 0.0973 - acc: 0.9618 - val_loss: 0.1592 - val_acc: 0.9419\n",
            "Epoch 18/25\n",
            "136/136 [==============================] - 67s 491ms/step - loss: 0.0862 - acc: 0.9642 - val_loss: 0.1459 - val_acc: 0.9434\n",
            "Epoch 19/25\n",
            "136/136 [==============================] - 67s 491ms/step - loss: 0.0924 - acc: 0.9677 - val_loss: 0.1407 - val_acc: 0.9419\n",
            "Epoch 20/25\n",
            "136/136 [==============================] - 67s 492ms/step - loss: 0.0865 - acc: 0.9688 - val_loss: 0.1492 - val_acc: 0.9434\n",
            "Epoch 21/25\n",
            "136/136 [==============================] - 67s 494ms/step - loss: 0.0690 - acc: 0.9775 - val_loss: 0.1356 - val_acc: 0.9471\n",
            "Epoch 22/25\n",
            "136/136 [==============================] - 67s 494ms/step - loss: 0.0683 - acc: 0.9776 - val_loss: 0.2445 - val_acc: 0.9206\n",
            "Epoch 23/25\n",
            "136/136 [==============================] - 67s 493ms/step - loss: 0.0757 - acc: 0.9716 - val_loss: 0.1596 - val_acc: 0.9382\n",
            "Epoch 24/25\n",
            "136/136 [==============================] - 67s 493ms/step - loss: 0.0686 - acc: 0.9780 - val_loss: 0.1468 - val_acc: 0.9485\n",
            "Epoch 25/25\n",
            "136/136 [==============================] - 67s 492ms/step - loss: 0.0641 - acc: 0.9773 - val_loss: 0.1448 - val_acc: 0.9478\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.9480614484272128\n",
            "Precision : 0.9480876784706332\n",
            "f1Score : 0.947163378010026\n",
            "[[315  54]\n",
            " [ 17 981]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwv2zvtWyX8r",
        "outputId": "8859b1f7-8772-4b32-c6d9-931af1743ff9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Metric----------Average---------StandardDeviation')\n",
        "print('Accuracy: ',np.mean(acc_avg),np.std(acc_avg))\n",
        "print('Precision:',np.mean(prec_avg),np.std(prec_avg))\n",
        "print('Recall:   ',np.mean(rec_avg),np.std(rec_avg))\n",
        "print('F1-score: ',np.mean(f1_agv),np.std(f1_agv))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Metric----------Average---------StandardDeviation\n",
            "Accuracy:  0.9522067788344306 0.0032896214492153268\n",
            "Precision: 0.9520060239327469 0.0031581225585723635\n",
            "F1-score:  0.9517120535329942 0.0035540189339799727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh2b2tit1Jh-",
        "outputId": "206fb7e1-0491-4b23-a0ee-00ede4e1148c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "my_metrics(true_classes, yPredictions)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy  : 0.9480614484272128\n",
            "Precision : 0.9478260869565217\n",
            "Recall : 0.9829659318637275\n",
            "f1Score : 0.9650762420068864\n",
            "[[315  54]\n",
            " [ 17 981]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9480614484272128,\n",
              " 0.9478260869565217,\n",
              " 0.9829659318637275,\n",
              " 0.9650762420068864)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}