{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Deep learning.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tcd-h0csCpOe"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hpuwVkH4MJX"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "import os, shutil\n",
        "from os import path\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import zipfile\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import models \n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd \n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from keras.preprocessing import image\n",
        "from keras import backend as K\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Set a random seed\n",
        "from numpy.random import seed\n",
        "seed(1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxQ6ipNwDDwK"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjBaSySh_W6c"
      },
      "source": [
        "#Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ5gAhuh5FUd",
        "outputId": "fb2b4f25-a6a7-492c-9cb7-5795656c8b98"
      },
      "source": [
        "#Choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('~/data')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "#Auto-iterate using the query syntax\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1tQbRH3uO-mwTbViQTNdzs_4x-UnUkoSz' in parents\"}).GetList()\n",
        "\n",
        "for f in file_list:\n",
        "  #Create & download by id.\n",
        "  print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  print('downloading to {}'.format(fname))\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)\n",
        "  break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: DataSet.zip, id: 1BeacQpDbIvJCk93KrpJxxsoeAcS_8ySo\n",
            "downloading to /root/data/DataSet.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWiG4_vp5z2S"
      },
      "source": [
        "with zipfile.ZipFile('/root/data/DataSet.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/root/data')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44Llx0GdDNaT"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnY31jz3AD6X"
      },
      "source": [
        "#Code used to reorganize the data in to new splits\n",
        "\n",
        "# #Move all data to the same folders\n",
        "\n",
        "# #Destination folders\n",
        "# dst_normal = 'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/AllData/NORMAL'\n",
        "# dst_pneumonia = 'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/AllData/PNEUMONIA'\n",
        "\n",
        "# #Original folders\n",
        "# src_normal = ['C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/val/NORMAL',\n",
        "#              'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/test/NORMAL',\n",
        "#              'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/train/NORMAL']\n",
        "\n",
        "# src_pneumonia = ['C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/val/PNEUMONIA',\n",
        "#              'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/test/PNEUMONIA',\n",
        "#              'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/train/PNEUMONIA']\n",
        "\n",
        "# #Loop to copy data from original folders to destination folders\n",
        "# for j in src_normal:\n",
        "#     files = [i for i in os.listdir(j)]\n",
        "#     for f in files:\n",
        "#         shutil.copy(path.join(j, f), dst_normal)\n",
        "        \n",
        "# for j in src_pneumonia:\n",
        "#     files = [i for i in os.listdir(j)]\n",
        "#     for f in files:\n",
        "#         shutil.copy(path.join(j, f), dst_pneumonia)\n",
        "\n",
        "# #Create train, val, test split (70, 15, 15)\n",
        "\n",
        "# #Destination folders\n",
        "# dst_normal = ['C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet/train/NORMAL',\n",
        "#              'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet/val/NORMAL',\n",
        "#              'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet/test/NORMAL']\n",
        "\n",
        "# dst_pneumonia = ['C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet/train/PNEUMONIA',\n",
        "#              'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet/val/PNEUMONIA',\n",
        "#              'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet/test/PNEUMONIA']\n",
        "\n",
        "# #Source folders\n",
        "# src_normal = 'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/AllData/NORMAL'\n",
        "# src_pneumonia = 'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/AllData/PNEUMONIA'\n",
        "\n",
        "# #Files (images) in source folders\n",
        "# files_normal = [i for i in os.listdir(src_normal)]\n",
        "# files_pneumonia = [i for i in os.listdir(src_pneumonia)]\n",
        "\n",
        "# #Counters\n",
        "# count_normal = 1\n",
        "# count_pneumonia = 1\n",
        "\n",
        "# #Loops to copy images to destination folders\n",
        "# for f in files_normal:\n",
        "#     if count_normal <= 1108:\n",
        "#         shutil.copy(path.join(src_normal, f), dst_normal[0]) \n",
        "#     elif count_normal <= (1108+238):\n",
        "#         shutil.copy(path.join(src_normal, f), dst_normal[1])\n",
        "#     else:\n",
        "#         shutil.copy(path.join(src_normal, f), dst_normal[2])\n",
        "#     count_normal = count_normal + 1\n",
        "    \n",
        "# for f in files_pneumonia:\n",
        "#     if count_pneumonia <= 2993:\n",
        "#         shutil.copy(path.join(src_pneumonia, f), dst_pneumonia[0]) \n",
        "#     elif count_pneumonia <= (2993+640):\n",
        "#         shutil.copy(path.join(src_pneumonia, f), dst_pneumonia[1])\n",
        "#     else:\n",
        "#         shutil.copy(path.join(src_pneumonia, f), dst_pneumonia[2])\n",
        "#     count_pneumonia = count_pneumonia + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIxR-YssU7_O"
      },
      "source": [
        "#Code used to produce oversampling dataset trough data augmentation\n",
        "\n",
        "#Data augmentation used\n",
        "# train_augment_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "#                                   rotation_range=40,\n",
        "#                                   width_shift_range=0.2,\n",
        "#                                   height_shift_range=0.2,\n",
        "#                                   shear_range=0.2,\n",
        "#                                   zoom_range=0.2,\n",
        "#                                   fill_mode='nearest')\n",
        "\n",
        "# train_augment_set = train_augment_datagen.flow_from_directory('C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet/train/', \n",
        "#                                                  target_size = (75, 75),\n",
        "#                                                  batch_size = 20,\n",
        "#                                                  class_mode = 'binary',\n",
        "                                                 \n",
        "#                                                 )\n",
        "\n",
        "# count = 1\n",
        "\n",
        "# for images, labels in train_augment_set:\n",
        "#     for i in range(20):\n",
        "#         if labels[i] == 0: #If the data augmented image is of the minority label, save itt\n",
        "#             matplotlib.image.imsave('C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet_DataAugOversampling/train/NORMAL/augmented'+str(count)+'.jpeg', images[i])\n",
        "#             count = count + 1\n",
        "#             if count >= 1885: #When the desired number of images are created aand saved, stop the loop\n",
        "#                 break\n",
        "#     if count >= 1885:\n",
        "#         break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZUzTSo7DZoU"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bbl3h3wDsMa",
        "outputId": "fa0a53cd-8bd4-4336-8907-6f52a5918976"
      },
      "source": [
        "train_set = train_datagen.flow_from_directory('/root/data/DataSet/train/', \n",
        "                                                 target_size = (75, 75),\n",
        "                                                 batch_size = 20,\n",
        "                                                 class_mode = 'binary',\n",
        "                                                 seed=1\n",
        "                                                )\n",
        "\n",
        "val_set = val_datagen.flow_from_directory('/root/data/DataSet/val/', \n",
        "                                            target_size = (75, 75),\n",
        "                                            batch_size = 20,\n",
        "                                            class_mode = 'binary',\n",
        "                                            seed=1\n",
        "                                           )\n",
        "\n",
        "val_set_cm = val_datagen.flow_from_directory('/root/data/DataSet/val/', \n",
        "                                            target_size = (75, 75),\n",
        "                                            batch_size = 1,\n",
        "                                            class_mode = 'binary',\n",
        "                                            seed=1,\n",
        "                                            shuffle=False\n",
        "                                           )\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/root/data/DataSet/test/', \n",
        "                                            target_size = (75, 75),\n",
        "                                            batch_size = 20,\n",
        "                                            class_mode = 'binary',\n",
        "                                            seed=1,\n",
        "                                            shuffle = False\n",
        "                                           )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4101 images belonging to 2 classes.\n",
            "Found 878 images belonging to 2 classes.\n",
            "Found 878 images belonging to 2 classes.\n",
            "Found 877 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHIJpp7NDTUg"
      },
      "source": [
        "# Model Creation and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSn2pyKJvSXl"
      },
      "source": [
        "#callbacks_list = [keras.callbacks.TensorBoard(log_dir='secondTheme/my_log_dir', histogram_freq=1)]\n",
        "\n",
        "\n",
        "callbacks_list= [keras.callbacks.EarlyStopping(monitor = 'acc', patience=3), \n",
        "                 keras.callbacks.ModelCheckpoint(filepath=\"/root/data/DataSet/my_model.h5\", monitor =\"val_loss\", save_best_only=True)]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsj5fdZe4JOP"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(75,75,3)))\n",
        "model.add(layers.MaxPooling2D((2,2), strides=2))\n",
        "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2), strides=2))\n",
        "model.add(layers.Flatten())\n",
        "#model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "#model.add(layers.Dense(512, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001), activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WevBssSXC21"
      },
      "source": [
        "#model = models.load_model('/root/data/ReducedInputSizeModel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HheOplUw4JOV",
        "outputId": "d8a81b87-f850-4b61-e353-dbe378590166"
      },
      "source": [
        "hist= model.fit(\n",
        "        train_set,\n",
        "        steps_per_epoch= 205,\n",
        "        epochs= 50,\n",
        "        validation_data=val_set,\n",
        "        validation_steps=43, \n",
        "        callbacks=callbacks_list\n",
        "        )"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "205/205 [==============================] - 84s 407ms/step - loss: 0.5176 - acc: 0.7586 - val_loss: 0.2369 - val_acc: 0.9547\n",
            "Epoch 2/50\n",
            "205/205 [==============================] - 83s 405ms/step - loss: 0.2663 - acc: 0.8965 - val_loss: 0.1482 - val_acc: 0.9663\n",
            "Epoch 3/50\n",
            "205/205 [==============================] - 83s 407ms/step - loss: 0.1989 - acc: 0.9243 - val_loss: 0.2211 - val_acc: 0.9000\n",
            "Epoch 4/50\n",
            "205/205 [==============================] - 83s 405ms/step - loss: 0.1829 - acc: 0.9264 - val_loss: 0.0859 - val_acc: 0.9802\n",
            "Epoch 5/50\n",
            "205/205 [==============================] - 83s 404ms/step - loss: 0.1558 - acc: 0.9392 - val_loss: 0.0889 - val_acc: 0.9733\n",
            "Epoch 6/50\n",
            "205/205 [==============================] - 82s 399ms/step - loss: 0.1533 - acc: 0.9356 - val_loss: 0.0784 - val_acc: 0.9744\n",
            "Epoch 7/50\n",
            "205/205 [==============================] - 81s 394ms/step - loss: 0.1433 - acc: 0.9484 - val_loss: 0.1028 - val_acc: 0.9628\n",
            "Epoch 8/50\n",
            "205/205 [==============================] - 81s 393ms/step - loss: 0.1400 - acc: 0.9492 - val_loss: 0.1033 - val_acc: 0.9605\n",
            "Epoch 9/50\n",
            "205/205 [==============================] - 81s 393ms/step - loss: 0.1298 - acc: 0.9500 - val_loss: 0.0752 - val_acc: 0.9767\n",
            "Epoch 10/50\n",
            "205/205 [==============================] - 80s 390ms/step - loss: 0.1411 - acc: 0.9470 - val_loss: 0.0752 - val_acc: 0.9744\n",
            "Epoch 11/50\n",
            "205/205 [==============================] - 83s 402ms/step - loss: 0.1310 - acc: 0.9525 - val_loss: 0.0914 - val_acc: 0.9628\n",
            "Epoch 12/50\n",
            "205/205 [==============================] - 82s 399ms/step - loss: 0.1257 - acc: 0.9535 - val_loss: 0.0863 - val_acc: 0.9674\n",
            "Epoch 13/50\n",
            "205/205 [==============================] - 81s 396ms/step - loss: 0.1124 - acc: 0.9549 - val_loss: 0.1441 - val_acc: 0.9407\n",
            "Epoch 14/50\n",
            "205/205 [==============================] - 83s 403ms/step - loss: 0.1115 - acc: 0.9578 - val_loss: 0.0827 - val_acc: 0.9686\n",
            "Epoch 15/50\n",
            "205/205 [==============================] - 83s 404ms/step - loss: 0.0958 - acc: 0.9640 - val_loss: 0.0676 - val_acc: 0.9779\n",
            "Epoch 16/50\n",
            "205/205 [==============================] - 82s 401ms/step - loss: 0.0991 - acc: 0.9615 - val_loss: 0.0766 - val_acc: 0.9721\n",
            "Epoch 17/50\n",
            "205/205 [==============================] - 83s 407ms/step - loss: 0.0900 - acc: 0.9644 - val_loss: 0.0817 - val_acc: 0.9733\n",
            "Epoch 18/50\n",
            "205/205 [==============================] - 84s 408ms/step - loss: 0.0918 - acc: 0.9618 - val_loss: 0.0672 - val_acc: 0.9791\n",
            "Epoch 19/50\n",
            "205/205 [==============================] - 83s 406ms/step - loss: 0.0868 - acc: 0.9687 - val_loss: 0.0653 - val_acc: 0.9779\n",
            "Epoch 20/50\n",
            "205/205 [==============================] - 83s 405ms/step - loss: 0.0893 - acc: 0.9690 - val_loss: 0.0726 - val_acc: 0.9698\n",
            "Epoch 21/50\n",
            "205/205 [==============================] - 82s 400ms/step - loss: 0.0799 - acc: 0.9747 - val_loss: 0.1036 - val_acc: 0.9686\n",
            "Epoch 22/50\n",
            "205/205 [==============================] - 83s 403ms/step - loss: 0.0793 - acc: 0.9698 - val_loss: 0.0641 - val_acc: 0.9779\n",
            "Epoch 23/50\n",
            "205/205 [==============================] - 83s 405ms/step - loss: 0.0802 - acc: 0.9707 - val_loss: 0.0684 - val_acc: 0.9721\n",
            "Epoch 24/50\n",
            "205/205 [==============================] - 83s 404ms/step - loss: 0.0771 - acc: 0.9711 - val_loss: 0.0647 - val_acc: 0.9767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF8NUwdkFFbf"
      },
      "source": [
        "# Model Assessment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XocTFY634JOW"
      },
      "source": [
        "acc = hist.history['acc']\n",
        "val_acc = hist.history['val_acc']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc)+1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kSiv_KMUFO0"
      },
      "source": [
        "#model.save('/root/data/ReducedInputSizeModel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uxovqcs4JOX",
        "outputId": "e1976cc2-6ed2-4b09-8ae6-0c30aa78176b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Y_pred = model.predict(val_set_cm,878) # ceil(num_of_test_samples / batch_size)\n",
        "Y_pred = (Y_pred>0.5)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(val_set_cm.classes, Y_pred))\n",
        "print('Classification Report')\n",
        "target_names = ['PlaceHolder', 'PlaceHolder']\n",
        "print(classification_report(val_set_cm.classes, Y_pred, target_names=target_names))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[228  10]\n",
            " [ 10 630]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " PlaceHolder       0.96      0.96      0.96       238\n",
            " PlaceHolder       0.98      0.98      0.98       640\n",
            "\n",
            "    accuracy                           0.98       878\n",
            "   macro avg       0.97      0.97      0.97       878\n",
            "weighted avg       0.98      0.98      0.98       878\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X4arQRgwJQ-"
      },
      "source": [
        "img_path = 'C:/Users/Eurico/Documents/DeepLearning/secondTheme/chest_xray/DataSet/test/PNEUMONIA/person69_bacteria_338.jpeg'\n",
        "\n",
        "img = image.load_img(img_path, target_size=(75,75))\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "x = x/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "intdWr1iwWir"
      },
      "source": [
        "#Taken from https://keras.io/examples/vision/grad_cam/\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer as well as the output predictions\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # This is the gradient of the output neuron (top predicted or chosen)\n",
        "    # with regard to the output feature map of the last conv layer\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    # then sum all the channels to obtain the heatmap class activation\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChJfnYNywZx0"
      },
      "source": [
        "# Generate class activation heatmap\n",
        "#heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "heatmap = make_gradcam_heatmap(x, model, 'conv2d_7')\n",
        "\n",
        "# Display heatmap\n",
        "plt.matshow(heatmap)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRkc7lA_wb7i"
      },
      "source": [
        "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
        "    # Load the original image\n",
        "    img = keras.preprocessing.image.load_img(img_path)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Use jet colormap to colorize heatmap\n",
        "    jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "    # Use RGB values of the colormap\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    # Create an image with RGB colorized heatmap\n",
        "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Superimpose the heatmap on original image\n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "    # Save the superimposed image\n",
        "    superimposed_img.save(cam_path)\n",
        "\n",
        "    # Display Grad CAM\n",
        "    display(Image(cam_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdfRf-S3wfLA"
      },
      "source": [
        "save_and_display_gradcam(img_path, heatmap)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}